{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import main_classificaiton as mc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
<<<<<<< HEAD
    "import random\n",
    "from sklearn.metrics import classification_report"
=======
    "import random"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c4dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & LSTM model \n",
    "config1 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation & GRU model \n",
    "config2 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & CNN_1D model \n",
    "config3 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
<<<<<<< HEAD
=======
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & CNN_1D model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
<<<<<<< HEAD
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & LSTM_FCNs model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM_FCNs', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 1, # recurrnet layers의 수, Default : 1\n",
    "            'lstm_drop_out' : 0.4, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'fc_drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 256, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
=======
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "config5 = {\n",
    "        'with_representation': True, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
<<<<<<< HEAD
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
=======
    "            'input_representation' : 0, # 예를 들면 (80, 20) 차원의 벡터 (80은 window_length에 따른 관측치 수, 20은 representation 특징벡터 차원 수)를 넣어야 함. 지금은 loader부분에서 random값들어가 있음\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# Raw data \n",
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'X_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'X_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
<<<<<<< HEAD
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
=======
    "print(train_y.shape) #shape : (num_of_instance x input_dims x window_size) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947)"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564b0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
<<<<<<< HEAD
      "train Loss: 1.7789 Acc: 0.2663\n",
      "val Loss: 1.7555 Acc: 0.3569\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0515 Acc: 0.5273\n",
      "val Loss: 1.1120 Acc: 0.5574\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9011 Acc: 0.6179\n",
      "val Loss: 0.9829 Acc: 0.6071\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.7906 Acc: 0.6473\n",
      "val Loss: 0.7324 Acc: 0.6717\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.6235 Acc: 0.7009\n",
      "val Loss: 0.6675 Acc: 0.6540\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5685 Acc: 0.7247\n",
      "val Loss: 0.6062 Acc: 0.7077\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5548 Acc: 0.7473\n",
      "val Loss: 0.6014 Acc: 0.7077\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.5036 Acc: 0.7701\n",
      "val Loss: 0.5988 Acc: 0.7315\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.4671 Acc: 0.7961\n",
      "val Loss: 0.5340 Acc: 0.7668\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.4766 Acc: 0.7903\n",
      "val Loss: 0.5355 Acc: 0.7648\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.4500 Acc: 0.7966\n",
      "val Loss: 0.5546 Acc: 0.7709\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.4335 Acc: 0.8104\n",
      "val Loss: 0.5610 Acc: 0.7757\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.4243 Acc: 0.8150\n",
      "val Loss: 0.6111 Acc: 0.7736\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.4101 Acc: 0.8220\n",
      "val Loss: 0.4941 Acc: 0.8083\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.3858 Acc: 0.8339\n",
      "val Loss: 0.4822 Acc: 0.8185\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.3810 Acc: 0.8380\n",
      "val Loss: 0.4761 Acc: 0.8103\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.3500 Acc: 0.8488\n",
      "val Loss: 0.4839 Acc: 0.8137\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.3218 Acc: 0.8601\n",
      "val Loss: 0.4485 Acc: 0.8253\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.3052 Acc: 0.8704\n",
      "val Loss: 0.4361 Acc: 0.8362\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.2712 Acc: 0.8890\n",
      "val Loss: 0.3961 Acc: 0.8593\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.2477 Acc: 0.9058\n",
      "val Loss: 0.3794 Acc: 0.8790\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.2107 Acc: 0.9279\n",
      "val Loss: 0.3390 Acc: 0.9075\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1688 Acc: 0.9383\n",
      "val Loss: 0.3230 Acc: 0.9177\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1453 Acc: 0.9480\n",
      "val Loss: 0.2621 Acc: 0.9198\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1281 Acc: 0.9520\n",
      "val Loss: 0.2608 Acc: 0.9320\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1074 Acc: 0.9560\n",
      "val Loss: 0.2462 Acc: 0.9218\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1059 Acc: 0.9543\n",
      "val Loss: 0.2440 Acc: 0.9130\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0953 Acc: 0.9577\n",
      "val Loss: 0.2492 Acc: 0.9184\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0955 Acc: 0.9578\n",
      "val Loss: 0.2684 Acc: 0.9171\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0956 Acc: 0.9580\n",
      "val Loss: 0.2446 Acc: 0.9205\n",
      "Training complete in 4m 35s\n",
      "Best val Acc: 0.932019\n",
      "[4 4 4 4 4]\n",
      "[[3.1428826e-03 3.8197242e-05 1.9060582e-05 3.0262794e-03 9.9377233e-01\n",
      "  1.2182280e-06]\n",
      " [4.1432492e-03 4.3443866e-05 2.0092155e-05 2.5938053e-03 9.9319845e-01\n",
      "  9.1327803e-07]\n",
      " [3.7461284e-03 4.0831965e-05 1.9313755e-05 2.6819711e-03 9.9351078e-01\n",
      "  9.5121305e-07]\n",
      " [4.6638870e-03 4.5634115e-05 2.0469381e-05 2.4181218e-03 9.9285114e-01\n",
      "  7.9520919e-07]\n",
      " [4.0701623e-03 4.2379208e-05 1.9275158e-05 2.5371381e-03 9.9333018e-01\n",
      "  8.7419880e-07]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.900844    0.759398    0.807018    0.785311    0.878378   \n",
      "recall       0.860887    0.857749    0.876190    0.849287    0.733083   \n",
      "f1-score     0.880412    0.805583    0.840183    0.816047    0.799180   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000   0.85375     0.855158      0.859629  \n",
      "recall       0.949721   0.85375     0.854486      0.853750  \n",
      "f1-score     0.974212   0.85375     0.852603      0.854423  \n",
      "support    537.000000   0.85375  2947.000000   2947.000000  \n"
=======
      "train Loss: 1.6574 Acc: 0.3578\n",
      "val Loss: 1.4503 Acc: 0.3848\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0065 Acc: 0.5565\n",
      "val Loss: 1.0774 Acc: 0.5391\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9592 Acc: 0.5877\n",
      "val Loss: 1.0034 Acc: 0.5670\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.9334 Acc: 0.6057\n",
      "val Loss: 1.0058 Acc: 0.5778\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.8719 Acc: 0.6354\n",
      "val Loss: 0.9964 Acc: 0.6213\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.6879 Acc: 0.7171\n",
      "val Loss: 0.7186 Acc: 0.7458\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5052 Acc: 0.8101\n",
      "val Loss: 0.5891 Acc: 0.8212\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4008 Acc: 0.8599\n",
      "val Loss: 0.5279 Acc: 0.8484\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3466 Acc: 0.8808\n",
      "val Loss: 0.4705 Acc: 0.8627\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3060 Acc: 0.8973\n",
      "val Loss: 0.3717 Acc: 0.8906\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2752 Acc: 0.9112\n",
      "val Loss: 0.3496 Acc: 0.9130\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2896 Acc: 0.8980\n",
      "val Loss: 0.2873 Acc: 0.9211\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2468 Acc: 0.9223\n",
      "val Loss: 0.3164 Acc: 0.9103\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2346 Acc: 0.9257\n",
      "val Loss: 0.2714 Acc: 0.9279\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.2216 Acc: 0.9286\n",
      "val Loss: 0.3622 Acc: 0.8933\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.2056 Acc: 0.9299\n",
      "val Loss: 0.2824 Acc: 0.9171\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1880 Acc: 0.9371\n",
      "val Loss: 0.2582 Acc: 0.9266\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1922 Acc: 0.9362\n",
      "val Loss: 0.2600 Acc: 0.9245\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.2443 Acc: 0.9158\n",
      "val Loss: 0.3305 Acc: 0.8906\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1791 Acc: 0.9408\n",
      "val Loss: 0.2492 Acc: 0.9293\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1756 Acc: 0.9398\n",
      "val Loss: 0.2403 Acc: 0.9320\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.2708 Acc: 0.9116\n",
      "val Loss: 0.3683 Acc: 0.9048\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1645 Acc: 0.9444\n",
      "val Loss: 0.2388 Acc: 0.9286\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1549 Acc: 0.9476\n",
      "val Loss: 0.2439 Acc: 0.9300\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1893 Acc: 0.9357\n",
      "val Loss: 0.2308 Acc: 0.9239\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1640 Acc: 0.9417\n",
      "val Loss: 0.2323 Acc: 0.9341\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1593 Acc: 0.9432\n",
      "val Loss: 0.2359 Acc: 0.9347\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1837 Acc: 0.9371\n",
      "val Loss: 0.2484 Acc: 0.9164\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1420 Acc: 0.9500\n",
      "val Loss: 0.2449 Acc: 0.9307\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.1551 Acc: 0.9458\n",
      "val Loss: 0.2475 Acc: 0.9225\n",
      "Training complete in 3m 17s\n",
      "Best val Acc: 0.936098\n",
      "[4 4 4 4 4]\n",
      "[[4.5214836e-03 1.5004937e-04 3.3503795e-05 8.2635731e-03 9.8703116e-01\n",
      "  2.0977977e-07]\n",
      " [4.9505834e-03 1.5442492e-04 3.3928223e-05 6.8437709e-03 9.8801708e-01\n",
      "  1.7939905e-07]\n",
      " [6.3765557e-03 1.7957440e-04 3.8538466e-05 5.6916475e-03 9.8771358e-01\n",
      "  1.7165915e-07]\n",
      " [5.4079797e-03 1.4515381e-04 3.6949557e-05 5.5562123e-03 9.8885357e-01\n",
      "  1.3897717e-07]\n",
      " [5.1595904e-03 1.3919613e-04 3.6768564e-05 5.7154642e-03 9.8894894e-01\n",
      "  1.4125800e-07]]\n"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
     ]
    }
   ],
   "source": [
    "# Case 1. w/o data representation & LSTM\n",
    "config = config1\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
<<<<<<< HEAD
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
=======
    "print(prob[:5]) # shape : (2947, 6)"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
<<<<<<< HEAD
      "train Loss: 1.7381 Acc: 0.2835\n",
      "val Loss: 1.6610 Acc: 0.3725\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0349 Acc: 0.5535\n",
      "val Loss: 1.1303 Acc: 0.5670\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.7380 Acc: 0.7028\n",
      "val Loss: 0.7783 Acc: 0.6988\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.4793 Acc: 0.7851\n",
      "val Loss: 0.5477 Acc: 0.7879\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.4056 Acc: 0.8165\n",
      "val Loss: 0.5346 Acc: 0.7865\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.3649 Acc: 0.8427\n",
      "val Loss: 0.5201 Acc: 0.8239\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.3154 Acc: 0.8842\n",
      "val Loss: 0.4668 Acc: 0.8804\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.2150 Acc: 0.9359\n",
      "val Loss: 0.2604 Acc: 0.9354\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1714 Acc: 0.9444\n",
      "val Loss: 0.2349 Acc: 0.9381\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1570 Acc: 0.9434\n",
      "val Loss: 0.2270 Acc: 0.9395\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1436 Acc: 0.9447\n",
      "val Loss: 0.2231 Acc: 0.9381\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1376 Acc: 0.9463\n",
      "val Loss: 0.2210 Acc: 0.9388\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1270 Acc: 0.9497\n",
      "val Loss: 0.2103 Acc: 0.9415\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1179 Acc: 0.9519\n",
      "val Loss: 0.2121 Acc: 0.9381\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1155 Acc: 0.9519\n",
      "val Loss: 0.2328 Acc: 0.9307\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1156 Acc: 0.9510\n",
      "val Loss: 0.2119 Acc: 0.9409\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1122 Acc: 0.9481\n",
      "val Loss: 0.2383 Acc: 0.9273\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1033 Acc: 0.9554\n",
      "val Loss: 0.2104 Acc: 0.9402\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1064 Acc: 0.9544\n",
      "val Loss: 0.2250 Acc: 0.9334\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1008 Acc: 0.9572\n",
      "val Loss: 0.2205 Acc: 0.9368\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0957 Acc: 0.9617\n",
      "val Loss: 0.2076 Acc: 0.9415\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1027 Acc: 0.9570\n",
      "val Loss: 0.2142 Acc: 0.9381\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0930 Acc: 0.9626\n",
      "val Loss: 0.2060 Acc: 0.9354\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0988 Acc: 0.9582\n",
      "val Loss: 0.2097 Acc: 0.9327\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0946 Acc: 0.9599\n",
      "val Loss: 0.2051 Acc: 0.9320\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0914 Acc: 0.9619\n",
      "val Loss: 0.2087 Acc: 0.9388\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0948 Acc: 0.9594\n",
      "val Loss: 0.2203 Acc: 0.9347\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0899 Acc: 0.9626\n",
      "val Loss: 0.2163 Acc: 0.9361\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0883 Acc: 0.9641\n",
      "val Loss: 0.2337 Acc: 0.9307\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0989 Acc: 0.9568\n",
      "val Loss: 0.2288 Acc: 0.9313\n",
      "Training complete in 4m 4s\n",
      "Best val Acc: 0.942216\n",
      "[4 4 4 4 4]\n",
      "[[6.6147130e-03 4.3342070e-04 4.0883242e-06 3.1474165e-03 9.8979467e-01\n",
      "  5.6110716e-06]\n",
      " [4.1247495e-03 2.2937769e-04 2.0818159e-06 3.8583579e-03 9.9177963e-01\n",
      "  5.7735538e-06]\n",
      " [4.1023437e-03 2.3258195e-04 2.0553646e-06 3.8146349e-03 9.9184263e-01\n",
      "  5.8144237e-06]\n",
      " [4.1173976e-03 2.3404945e-04 2.0422199e-06 3.7382224e-03 9.9190253e-01\n",
      "  5.8004416e-06]\n",
      " [4.1938112e-03 2.4798021e-04 2.0607722e-06 3.5429583e-03 9.9200737e-01\n",
      "  5.8068881e-06]]\n",
      "                  0.0         1.0         2.0         3.0         4.0    5.0  \\\n",
      "precision    0.871940    0.940774    0.903073    0.824945    0.800000    1.0   \n",
      "recall       0.933468    0.876858    0.909524    0.767821    0.842105    1.0   \n",
      "f1-score     0.901655    0.907692    0.906287    0.795359    0.820513    1.0   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000  537.0   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision   0.88904     0.890122      0.889897  \n",
      "recall      0.88904     0.888296      0.889040  \n",
      "f1-score    0.88904     0.888584      0.888842  \n",
      "support     0.88904  2947.000000   2947.000000  \n"
=======
      "train Loss: 1.7734 Acc: 0.2931\n",
      "val Loss: 1.7412 Acc: 0.3018\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0326 Acc: 0.5496\n",
      "val Loss: 1.0919 Acc: 0.5534\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9024 Acc: 0.6183\n",
      "val Loss: 0.9183 Acc: 0.6649\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.9062 Acc: 0.6169\n",
      "val Loss: 0.8528 Acc: 0.6880\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.7794 Acc: 0.6883\n",
      "val Loss: 0.8394 Acc: 0.7124\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.7871 Acc: 0.6541\n",
      "val Loss: 0.9775 Acc: 0.5846\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.7142 Acc: 0.6864\n",
      "val Loss: 0.7888 Acc: 0.6886\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.6371 Acc: 0.7419\n",
      "val Loss: 0.6810 Acc: 0.7444\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.6682 Acc: 0.7421\n",
      "val Loss: 0.7087 Acc: 0.7315\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.5376 Acc: 0.7832\n",
      "val Loss: 0.6536 Acc: 0.7322\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.5593 Acc: 0.7653\n",
      "val Loss: 0.5823 Acc: 0.7587\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.4992 Acc: 0.7890\n",
      "val Loss: 0.5864 Acc: 0.7723\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.4589 Acc: 0.8147\n",
      "val Loss: 0.5428 Acc: 0.7899\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.5841 Acc: 0.7633\n",
      "val Loss: 0.6265 Acc: 0.7661\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.9747 Acc: 0.6048\n",
      "val Loss: 0.9504 Acc: 0.6601\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.8185 Acc: 0.6390\n",
      "val Loss: 0.7326 Acc: 0.6751\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 1.0357 Acc: 0.5724\n",
      "val Loss: 1.0632 Acc: 0.5527\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.7707 Acc: 0.6402\n",
      "val Loss: 0.8157 Acc: 0.6649\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.7273 Acc: 0.6669\n",
      "val Loss: 0.7774 Acc: 0.6703\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.7370 Acc: 0.6643\n",
      "val Loss: 0.7219 Acc: 0.6914\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.5829 Acc: 0.7456\n",
      "val Loss: 0.5626 Acc: 0.7621\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.4625 Acc: 0.8065\n",
      "val Loss: 0.4900 Acc: 0.8063\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.5061 Acc: 0.7869\n",
      "val Loss: 0.5240 Acc: 0.7913\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.4248 Acc: 0.8327\n",
      "val Loss: 0.4651 Acc: 0.8300\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.5297 Acc: 0.7728\n",
      "val Loss: 0.5007 Acc: 0.7899\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.3707 Acc: 0.8628\n",
      "val Loss: 0.4090 Acc: 0.8491\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.3227 Acc: 0.8825\n",
      "val Loss: 0.4105 Acc: 0.8443\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.2921 Acc: 0.8924\n",
      "val Loss: 0.4024 Acc: 0.8457\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.2527 Acc: 0.9080\n",
      "val Loss: 0.3524 Acc: 0.8770\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.3912 Acc: 0.8585\n",
      "val Loss: 0.6833 Acc: 0.7158\n",
      "Training complete in 5m 9s\n",
      "Best val Acc: 0.903467\n",
      "[4 4 4 4 4]\n",
      "[[4.08150628e-02 4.82685026e-03 6.05355417e-05 2.26821308e-03\n",
      "  9.51980114e-01 4.92620056e-05]\n",
      " [1.84092752e-03 1.73389984e-04 6.27489862e-06 5.95301064e-03\n",
      "  9.92014647e-01 1.17181808e-05]\n",
      " [8.86968337e-04 7.29505919e-05 1.30653461e-05 1.46933170e-02\n",
      "  9.84327614e-01 6.11029827e-06]\n",
      " [7.98552763e-04 8.37308253e-05 8.70966414e-06 1.47835640e-02\n",
      "  9.84318018e-01 7.53098993e-06]\n",
      " [9.06702480e-04 7.17921066e-05 1.28198189e-05 1.35646695e-02\n",
      "  9.85438228e-01 5.87854493e-06]]\n"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
     ]
    }
   ],
   "source": [
    "# Case 2. w/o data representation & GRU\n",
    "config = config2\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
<<<<<<< HEAD
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
=======
    "print(prob[:5]) # shape : (2947, 6)"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7674f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
<<<<<<< HEAD
      "train Loss: 1.6921 Acc: 0.4606\n",
      "val Loss: 1.5258 Acc: 0.6220\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.5038 Acc: 0.8153\n",
      "val Loss: 0.6735 Acc: 0.8035\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.3418 Acc: 0.8772\n",
      "val Loss: 0.6024 Acc: 0.8389\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.2777 Acc: 0.8997\n",
      "val Loss: 0.5746 Acc: 0.8559\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2316 Acc: 0.9199\n",
      "val Loss: 0.5430 Acc: 0.8749\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1975 Acc: 0.9306\n",
      "val Loss: 0.5114 Acc: 0.8939\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1694 Acc: 0.9381\n",
      "val Loss: 0.4864 Acc: 0.9028\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1462 Acc: 0.9486\n",
      "val Loss: 0.4714 Acc: 0.9028\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1299 Acc: 0.9534\n",
      "val Loss: 0.4587 Acc: 0.9082\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1189 Acc: 0.9560\n",
      "val Loss: 0.4640 Acc: 0.9055\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1088 Acc: 0.9575\n",
      "val Loss: 0.4569 Acc: 0.9096\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1012 Acc: 0.9585\n",
      "val Loss: 0.4401 Acc: 0.9116\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.0946 Acc: 0.9597\n",
      "val Loss: 0.4293 Acc: 0.9109\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.0899 Acc: 0.9611\n",
      "val Loss: 0.4102 Acc: 0.9109\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.0862 Acc: 0.9624\n",
      "val Loss: 0.4008 Acc: 0.9109\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0839 Acc: 0.9640\n",
      "val Loss: 0.3955 Acc: 0.9082\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0802 Acc: 0.9631\n",
      "val Loss: 0.3775 Acc: 0.9123\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0795 Acc: 0.9648\n",
      "val Loss: 0.3650 Acc: 0.9130\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0753 Acc: 0.9657\n",
      "val Loss: 0.3571 Acc: 0.9164\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0736 Acc: 0.9657\n",
      "val Loss: 0.3620 Acc: 0.9171\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0698 Acc: 0.9675\n",
      "val Loss: 0.3570 Acc: 0.9239\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.0691 Acc: 0.9662\n",
      "val Loss: 0.3395 Acc: 0.9252\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0683 Acc: 0.9670\n",
      "val Loss: 0.3499 Acc: 0.9239\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0669 Acc: 0.9699\n",
      "val Loss: 0.3529 Acc: 0.9259\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0666 Acc: 0.9692\n",
      "val Loss: 0.3517 Acc: 0.9245\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0630 Acc: 0.9682\n",
      "val Loss: 0.3559 Acc: 0.9252\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0612 Acc: 0.9709\n",
      "val Loss: 0.3608 Acc: 0.9266\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0595 Acc: 0.9725\n",
      "val Loss: 0.3711 Acc: 0.9232\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0586 Acc: 0.9716\n",
      "val Loss: 0.3824 Acc: 0.9252\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0569 Acc: 0.9730\n",
      "val Loss: 0.3881 Acc: 0.9266\n",
      "Training complete in 0m 44s\n",
      "Best val Acc: 0.926581\n",
      "[4 4 4 4 4]\n",
      "[[1.3835733e-04 2.0991228e-04 1.1575056e-10 1.6110012e-04 9.9949062e-01\n",
      "  4.3692094e-12]\n",
      " [1.7275727e-04 1.2295740e-04 5.7558597e-11 1.2112593e-04 9.9958318e-01\n",
      "  1.3214138e-12]\n",
      " [5.2806929e-05 1.9448133e-04 2.5666153e-11 4.5264318e-05 9.9970740e-01\n",
      "  9.2810276e-13]\n",
      " [2.3459537e-05 2.5745551e-04 8.7912611e-12 3.0766307e-05 9.9968827e-01\n",
      "  8.3606901e-13]\n",
      " [9.8980026e-06 1.1235011e-04 1.7613328e-12 2.4049179e-05 9.9985373e-01\n",
      "  2.5974405e-13]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.965517    0.833969    0.879386    0.850103    0.895257   \n",
      "recall       0.903226    0.927813    0.954762    0.843177    0.851504   \n",
      "f1-score     0.933333    0.878392    0.915525    0.846626    0.872832   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000  0.903631     0.904039      0.906588  \n",
      "recall       0.949721  0.903631     0.905034      0.903631  \n",
      "f1-score     0.974212  0.903631     0.903487      0.904095  \n",
      "support    537.000000  0.903631  2947.000000   2947.000000  \n"
=======
      "train Loss: 1.7511 Acc: 0.3561\n",
      "val Loss: 1.6960 Acc: 0.4018\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9861 Acc: 0.5676\n",
      "val Loss: 1.1365 Acc: 0.5350\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.8708 Acc: 0.6320\n",
      "val Loss: 0.9467 Acc: 0.6383\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.6686 Acc: 0.7653\n",
      "val Loss: 0.6364 Acc: 0.8144\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.3027 Acc: 0.9106\n",
      "val Loss: 0.3224 Acc: 0.9300\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1912 Acc: 0.9401\n",
      "val Loss: 0.2573 Acc: 0.9395\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1561 Acc: 0.9471\n",
      "val Loss: 0.2446 Acc: 0.9388\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1395 Acc: 0.9480\n",
      "val Loss: 0.2414 Acc: 0.9402\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1350 Acc: 0.9536\n",
      "val Loss: 0.2387 Acc: 0.9341\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1310 Acc: 0.9480\n",
      "val Loss: 0.2515 Acc: 0.9402\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1219 Acc: 0.9534\n",
      "val Loss: 0.2522 Acc: 0.9395\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1228 Acc: 0.9539\n",
      "val Loss: 0.2619 Acc: 0.9368\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1180 Acc: 0.9539\n",
      "val Loss: 0.2590 Acc: 0.9375\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1070 Acc: 0.9543\n",
      "val Loss: 0.2559 Acc: 0.9388\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1031 Acc: 0.9580\n",
      "val Loss: 0.2562 Acc: 0.9375\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0993 Acc: 0.9616\n",
      "val Loss: 0.2511 Acc: 0.9395\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0993 Acc: 0.9590\n",
      "val Loss: 0.2497 Acc: 0.9354\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0993 Acc: 0.9599\n",
      "val Loss: 0.2479 Acc: 0.9347\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0949 Acc: 0.9629\n",
      "val Loss: 0.2530 Acc: 0.9375\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0930 Acc: 0.9617\n",
      "val Loss: 0.2526 Acc: 0.9402\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0895 Acc: 0.9633\n",
      "val Loss: 0.2572 Acc: 0.9395\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1033 Acc: 0.9594\n",
      "val Loss: 0.2587 Acc: 0.9381\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0879 Acc: 0.9628\n",
      "val Loss: 0.2631 Acc: 0.9375\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0872 Acc: 0.9633\n",
      "val Loss: 0.2622 Acc: 0.9368\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0851 Acc: 0.9628\n",
      "val Loss: 0.2667 Acc: 0.9368\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0843 Acc: 0.9640\n",
      "val Loss: 0.2664 Acc: 0.9381\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0870 Acc: 0.9623\n",
      "val Loss: 0.2735 Acc: 0.9375\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0899 Acc: 0.9592\n",
      "val Loss: 0.2725 Acc: 0.9375\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0835 Acc: 0.9611\n",
      "val Loss: 0.2707 Acc: 0.9381\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0816 Acc: 0.9643\n",
      "val Loss: 0.2712 Acc: 0.9368\n",
      "Training complete in 4m 19s\n",
      "Best val Acc: 0.940857\n",
      "[4 4 4 4 4]\n",
      "[[1.4380289e-02 1.8129022e-03 2.0217443e-05 1.0951811e-03 9.8266625e-01\n",
      "  2.5202655e-05]\n",
      " [1.3365337e-02 1.9776577e-03 1.9504199e-05 1.0490593e-03 9.8355931e-01\n",
      "  2.9114295e-05]\n",
      " [1.3895592e-02 2.0615186e-03 2.0235577e-05 1.0369056e-03 9.8295593e-01\n",
      "  2.9711655e-05]\n",
      " [1.4425054e-02 2.1313692e-03 2.0490825e-05 1.0150188e-03 9.8237765e-01\n",
      "  3.0370185e-05]\n",
      " [1.4831049e-02 2.2043064e-03 2.0943333e-05 9.9724007e-04 9.8191512e-01\n",
      "  3.1408563e-05]]\n"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
     ]
    }
   ],
   "source": [
    "# Case 3. w/o data representation & CNN_1D\n",
    "config = config3\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
<<<<<<< HEAD
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
=======
    "print(prob[:5]) # shape : (2947, 6)"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59275e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
<<<<<<< HEAD
      "train Loss: 1.6852 Acc: 0.4542\n",
      "val Loss: 1.7355 Acc: 0.5656\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.3337 Acc: 0.6819\n",
      "val Loss: 1.3285 Acc: 0.6567\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9891 Acc: 0.8062\n",
      "val Loss: 0.9974 Acc: 0.7927\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.8252 Acc: 0.9223\n",
      "val Loss: 0.8648 Acc: 0.8953\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.6896 Acc: 0.9415\n",
      "val Loss: 0.7679 Acc: 0.9007\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5904 Acc: 0.9546\n",
      "val Loss: 0.6917 Acc: 0.9028\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5156 Acc: 0.9594\n",
      "val Loss: 0.6275 Acc: 0.9041\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4533 Acc: 0.9619\n",
      "val Loss: 0.5726 Acc: 0.9048\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3985 Acc: 0.9636\n",
      "val Loss: 0.5319 Acc: 0.9048\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3537 Acc: 0.9638\n",
      "val Loss: 0.4924 Acc: 0.9055\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.3157 Acc: 0.9653\n",
      "val Loss: 0.4623 Acc: 0.9041\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2811 Acc: 0.9662\n",
      "val Loss: 0.4415 Acc: 0.9048\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2518 Acc: 0.9657\n",
      "val Loss: 0.4205 Acc: 0.9109\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2277 Acc: 0.9663\n",
      "val Loss: 0.4053 Acc: 0.9123\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.2063 Acc: 0.9689\n",
      "val Loss: 0.3944 Acc: 0.9055\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1851 Acc: 0.9694\n",
      "val Loss: 0.3769 Acc: 0.9055\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1673 Acc: 0.9711\n",
      "val Loss: 0.3709 Acc: 0.9150\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1527 Acc: 0.9728\n",
      "val Loss: 0.3486 Acc: 0.9164\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1367 Acc: 0.9755\n",
      "val Loss: 0.3437 Acc: 0.9062\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1245 Acc: 0.9745\n",
      "val Loss: 0.3472 Acc: 0.9150\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1119 Acc: 0.9755\n",
      "val Loss: 0.3311 Acc: 0.9171\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1052 Acc: 0.9760\n",
      "val Loss: 0.3166 Acc: 0.9130\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0958 Acc: 0.9782\n",
      "val Loss: 0.3069 Acc: 0.9177\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0925 Acc: 0.9770\n",
      "val Loss: 0.3151 Acc: 0.9177\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0847 Acc: 0.9781\n",
      "val Loss: 0.3031 Acc: 0.9198\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0868 Acc: 0.9793\n",
      "val Loss: 0.3029 Acc: 0.9211\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0811 Acc: 0.9772\n",
      "val Loss: 0.3113 Acc: 0.9123\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0707 Acc: 0.9811\n",
      "val Loss: 0.2875 Acc: 0.9252\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0707 Acc: 0.9784\n",
      "val Loss: 0.3027 Acc: 0.9062\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0613 Acc: 0.9842\n",
      "val Loss: 0.3015 Acc: 0.9157\n",
      "Training complete in 1m 33s\n",
      "Best val Acc: 0.932019\n",
      "[4 4 4 4 4]\n",
      "[[6.5858681e-03 3.0865753e-03 8.2912314e-04 9.1310067e-04 9.8856550e-01\n",
      "  1.9814664e-05]\n",
      " [1.5846780e-02 5.7159988e-03 1.8494719e-03 1.9806575e-03 9.7458148e-01\n",
      "  2.5617033e-05]\n",
      " [1.9886993e-02 7.2369594e-03 2.1636828e-03 2.8627983e-03 9.6782368e-01\n",
      "  2.5834570e-05]\n",
      " [1.8312940e-02 7.7453386e-03 1.7938456e-03 2.2900952e-03 9.6983778e-01\n",
      "  1.9999021e-05]\n",
      " [1.5127777e-02 6.5489658e-03 1.5352112e-03 1.6374437e-03 9.7513264e-01\n",
      "  1.7915218e-05]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.950397    0.971554    0.931264    0.875294    0.820000   \n",
      "recall       0.965726    0.942675    1.000000    0.757637    0.924812   \n",
      "f1-score     0.958000    0.956897    0.964409    0.812227    0.869258   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000  0.921955     0.924751      0.924038  \n",
      "recall       0.949721  0.921955     0.923429      0.921955  \n",
      "f1-score     0.974212  0.921955     0.922500      0.921384  \n",
      "support    537.000000  0.921955  2947.000000   2947.000000  \n"
=======
      "train Loss: 1.6331 Acc: 0.4045\n",
      "val Loss: 1.3934 Acc: 0.5398\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.5212 Acc: 0.7987\n",
      "val Loss: 0.6720 Acc: 0.8056\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.3854 Acc: 0.8604\n",
      "val Loss: 0.5499 Acc: 0.8368\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.3060 Acc: 0.8927\n",
      "val Loss: 0.4675 Acc: 0.8532\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2494 Acc: 0.9141\n",
      "val Loss: 0.4058 Acc: 0.8783\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.2069 Acc: 0.9306\n",
      "val Loss: 0.3791 Acc: 0.8865\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1786 Acc: 0.9386\n",
      "val Loss: 0.3540 Acc: 0.8967\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1568 Acc: 0.9466\n",
      "val Loss: 0.3402 Acc: 0.8994\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1403 Acc: 0.9522\n",
      "val Loss: 0.3284 Acc: 0.9055\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1274 Acc: 0.9558\n",
      "val Loss: 0.3223 Acc: 0.9103\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1179 Acc: 0.9578\n",
      "val Loss: 0.2973 Acc: 0.9205\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1107 Acc: 0.9595\n",
      "val Loss: 0.2925 Acc: 0.9218\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1022 Acc: 0.9606\n",
      "val Loss: 0.2865 Acc: 0.9211\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.0969 Acc: 0.9628\n",
      "val Loss: 0.2821 Acc: 0.9232\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.0933 Acc: 0.9628\n",
      "val Loss: 0.2863 Acc: 0.9211\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0878 Acc: 0.9641\n",
      "val Loss: 0.2839 Acc: 0.9225\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0840 Acc: 0.9641\n",
      "val Loss: 0.2888 Acc: 0.9259\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0804 Acc: 0.9655\n",
      "val Loss: 0.2895 Acc: 0.9259\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0784 Acc: 0.9658\n",
      "val Loss: 0.2922 Acc: 0.9252\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0755 Acc: 0.9662\n",
      "val Loss: 0.2954 Acc: 0.9225\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0736 Acc: 0.9670\n",
      "val Loss: 0.2986 Acc: 0.9361\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.0742 Acc: 0.9665\n",
      "val Loss: 0.2828 Acc: 0.9252\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0698 Acc: 0.9697\n",
      "val Loss: 0.2897 Acc: 0.9245\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0661 Acc: 0.9702\n",
      "val Loss: 0.2840 Acc: 0.9239\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0652 Acc: 0.9691\n",
      "val Loss: 0.3002 Acc: 0.9232\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0636 Acc: 0.9702\n",
      "val Loss: 0.3010 Acc: 0.9232\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0615 Acc: 0.9702\n",
      "val Loss: 0.2938 Acc: 0.9239\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0605 Acc: 0.9716\n",
      "val Loss: 0.2964 Acc: 0.9286\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0588 Acc: 0.9731\n",
      "val Loss: 0.2889 Acc: 0.9259\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0582 Acc: 0.9735\n",
      "val Loss: 0.2949 Acc: 0.9252\n",
      "Training complete in 0m 46s\n",
      "Best val Acc: 0.940177\n",
      "[4 4 4 4 4]\n",
      "[[4.9122332e-06 2.8034972e-05 2.2955086e-13 1.8831897e-05 9.9994826e-01\n",
      "  6.8109113e-14]\n",
      " [1.2523996e-05 3.6045538e-05 1.7067246e-13 8.2466970e-05 9.9986899e-01\n",
      "  4.1336472e-14]\n",
      " [8.5092443e-06 6.2387058e-05 2.3781855e-13 7.4034549e-05 9.9985504e-01\n",
      "  7.9870707e-14]\n",
      " [4.6790915e-06 8.4736566e-05 2.0288286e-13 5.2684180e-05 9.9985790e-01\n",
      "  1.2451327e-13]\n",
      " [1.8034656e-06 5.6174038e-05 8.0126525e-14 3.2506639e-05 9.9990952e-01\n",
      "  9.2559898e-14]]\n"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
     ]
    }
   ],
   "source": [
    "# Case 4. w/o data representation & LSTM_FCNs\n",
    "config = config4\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
<<<<<<< HEAD
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1a60a",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
=======
    "print(prob[:5]) # shape : (2947, 6)"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3085234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128)\n",
      "(7352,)\n",
      "(2947, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# Representation data\n",
    "data_dir = './data'\n",
    "\n",
    "train_x = pd.read_csv(os.path.join(data_dir, 'ts2vec_repr_train.csv'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "\n",
    "test_x = pd.read_csv(os.path.join(data_dir, 'ts2vec_repr_test.csv'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b370aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
<<<<<<< HEAD
      "train Loss: 1.6923 Acc: 0.3856\n",
      "val Loss: 1.6072 Acc: 0.5350\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9423 Acc: 0.6948\n",
      "val Loss: 0.8945 Acc: 0.7410\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.6747 Acc: 0.7614\n",
      "val Loss: 0.6682 Acc: 0.7791\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.5527 Acc: 0.8062\n",
      "val Loss: 0.5651 Acc: 0.8178\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.4724 Acc: 0.8357\n",
      "val Loss: 0.4980 Acc: 0.8321\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.4103 Acc: 0.8563\n",
      "val Loss: 0.4440 Acc: 0.8484\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.3651 Acc: 0.8786\n",
      "val Loss: 0.3966 Acc: 0.8790\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.3195 Acc: 0.8941\n",
      "val Loss: 0.3584 Acc: 0.8960\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.2863 Acc: 0.9044\n",
      "val Loss: 0.3313 Acc: 0.8939\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.2542 Acc: 0.9182\n",
      "val Loss: 0.3054 Acc: 0.9041\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2301 Acc: 0.9281\n",
      "val Loss: 0.2858 Acc: 0.9123\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2122 Acc: 0.9320\n",
      "val Loss: 0.2721 Acc: 0.9164\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1963 Acc: 0.9398\n",
      "val Loss: 0.2596 Acc: 0.9184\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1876 Acc: 0.9384\n",
      "val Loss: 0.2486 Acc: 0.9225\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1703 Acc: 0.9464\n",
      "val Loss: 0.2429 Acc: 0.9218\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1627 Acc: 0.9478\n",
      "val Loss: 0.2337 Acc: 0.9239\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1557 Acc: 0.9478\n",
      "val Loss: 0.2272 Acc: 0.9259\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1484 Acc: 0.9500\n",
      "val Loss: 0.2224 Acc: 0.9320\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1426 Acc: 0.9498\n",
      "val Loss: 0.2209 Acc: 0.9266\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1376 Acc: 0.9522\n",
      "val Loss: 0.2160 Acc: 0.9327\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1312 Acc: 0.9565\n",
      "val Loss: 0.2100 Acc: 0.9347\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1305 Acc: 0.9543\n",
      "val Loss: 0.2079 Acc: 0.9347\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1281 Acc: 0.9519\n",
      "val Loss: 0.2054 Acc: 0.9354\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1251 Acc: 0.9539\n",
      "val Loss: 0.2061 Acc: 0.9361\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1196 Acc: 0.9558\n",
      "val Loss: 0.2033 Acc: 0.9375\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1166 Acc: 0.9549\n",
      "val Loss: 0.2014 Acc: 0.9354\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1142 Acc: 0.9565\n",
      "val Loss: 0.2035 Acc: 0.9361\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1124 Acc: 0.9580\n",
      "val Loss: 0.2005 Acc: 0.9375\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1097 Acc: 0.9594\n",
      "val Loss: 0.2008 Acc: 0.9375\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.1108 Acc: 0.9561\n",
      "val Loss: 0.1993 Acc: 0.9375\n",
      "Training complete in 0m 25s\n",
      "Best val Acc: 0.938137\n",
      "[4 4 4 4 4]\n",
      "[[4.3652311e-05 3.2642618e-04 1.5995928e-06 6.6966298e-03 9.9292678e-01\n",
      "  4.8134893e-06]\n",
      " [4.7802228e-06 6.5756125e-05 3.8763639e-07 7.6732626e-03 9.9225473e-01\n",
      "  1.0959986e-06]\n",
      " [2.0228617e-06 4.7563150e-05 3.4184202e-07 9.7589809e-03 9.9019021e-01\n",
      "  9.4529292e-07]\n",
      " [2.6051623e-06 5.3089814e-05 3.5020051e-07 8.0245109e-03 9.9191850e-01\n",
      "  1.0092582e-06]\n",
      " [2.4374933e-06 5.9906775e-05 3.8326880e-07 7.8893155e-03 9.9204683e-01\n",
      "  1.0995636e-06]]\n",
      "                  0.0         1.0         2.0         3.0         4.0    5.0  \\\n",
      "precision    0.952965    0.960465    0.868922    0.828125    0.794737    1.0   \n",
      "recall       0.939516    0.876858    0.978571    0.755601    0.851504    1.0   \n",
      "f1-score     0.946193    0.916759    0.920493    0.790202    0.822142    1.0   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000  537.0   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision  0.899559     0.900869      0.901393  \n",
      "recall     0.899559     0.900342      0.899559  \n",
      "f1-score   0.899559     0.899298      0.899247  \n",
      "support    0.899559  2947.000000   2947.000000  \n"
=======
      "train Loss: 1.8034 Acc: 0.1852\n",
      "val Loss: 1.7961 Acc: 0.1869\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.7933 Acc: 0.1818\n",
      "val Loss: 1.7908 Acc: 0.1788\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 1.7917 Acc: 0.1823\n",
      "val Loss: 1.7904 Acc: 0.1788\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 1.7921 Acc: 0.1777\n",
      "val Loss: 1.7905 Acc: 0.1754\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 1.7912 Acc: 0.1877\n",
      "val Loss: 1.7905 Acc: 0.1727\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 1.7917 Acc: 0.1758\n",
      "val Loss: 1.7906 Acc: 0.1740\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 1.7906 Acc: 0.1785\n",
      "val Loss: 1.7909 Acc: 0.1761\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 1.7915 Acc: 0.1816\n",
      "val Loss: 1.7910 Acc: 0.1768\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 1.7904 Acc: 0.1787\n",
      "val Loss: 1.7911 Acc: 0.1774\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 1.7907 Acc: 0.1809\n",
      "val Loss: 1.7911 Acc: 0.1768\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 1.7910 Acc: 0.1760\n",
      "val Loss: 1.7911 Acc: 0.1768\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 1.7909 Acc: 0.1738\n",
      "val Loss: 1.7912 Acc: 0.1774\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 1.7903 Acc: 0.1753\n",
      "val Loss: 1.7912 Acc: 0.1774\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 1.7906 Acc: 0.1816\n",
      "val Loss: 1.7912 Acc: 0.1761\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 1.7905 Acc: 0.1804\n",
      "val Loss: 1.7911 Acc: 0.1761\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 1.7903 Acc: 0.1835\n",
      "val Loss: 1.7911 Acc: 0.1734\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 1.7904 Acc: 0.1804\n",
      "val Loss: 1.7911 Acc: 0.1754\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 1.7903 Acc: 0.1806\n",
      "val Loss: 1.7911 Acc: 0.1720\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 1.7902 Acc: 0.1751\n",
      "val Loss: 1.7911 Acc: 0.1734\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 1.7902 Acc: 0.1774\n",
      "val Loss: 1.7910 Acc: 0.1693\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 1.7899 Acc: 0.1826\n",
      "val Loss: 1.7910 Acc: 0.1706\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 1.7902 Acc: 0.1770\n",
      "val Loss: 1.7911 Acc: 0.1693\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 1.7901 Acc: 0.1789\n",
      "val Loss: 1.7910 Acc: 0.1713\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 1.7897 Acc: 0.1830\n",
      "val Loss: 1.7910 Acc: 0.1713\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 1.7897 Acc: 0.1801\n",
      "val Loss: 1.7910 Acc: 0.1720\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 1.7893 Acc: 0.1847\n",
      "val Loss: 1.7910 Acc: 0.1672\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 1.7895 Acc: 0.1811\n",
      "val Loss: 1.7911 Acc: 0.1672\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 1.7894 Acc: 0.1814\n",
      "val Loss: 1.7911 Acc: 0.1679\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 1.7896 Acc: 0.1809\n",
      "val Loss: 1.7911 Acc: 0.1672\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 1.7903 Acc: 0.1791\n",
      "val Loss: 1.7911 Acc: 0.1666\n",
      "Training complete in 0m 21s\n",
      "Best val Acc: 0.186948\n",
      "[4 4 4 4 4]\n",
      "[[0.1473428  0.1473428  0.1473428  0.1473428  0.26328596 0.1473428 ]\n",
      " [0.14828402 0.14828402 0.1488165  0.15319706 0.22886156 0.17255682]\n",
      " [0.149092   0.149092   0.149092   0.149092   0.22606935 0.17756262]\n",
      " [0.14488457 0.14488457 0.15058607 0.15093774 0.26382247 0.14488457]\n",
      " [0.15484491 0.15484491 0.15484491 0.15484491 0.22577547 0.15484491]]\n"
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
     ]
    }
   ],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
<<<<<<< HEAD
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43781a",
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "print(prob[:5]) # shape : (2947, 6)"
   ]
>>>>>>> d07f8f2287b498aaaec882ee2bd4ea0095340b9b
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
