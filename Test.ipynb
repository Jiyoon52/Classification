{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import main_classificaiton as mc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c4dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & RNN model \n",
    "config1 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'RNN', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 50, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 100 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation &LSTM model \n",
    "config2 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 50, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 100 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & GRU model \n",
    "config3 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 50, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 100 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & CNN_1D model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 50, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 100 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "# 특징 벡터의 사이즈 = 20 이라고 가정\n",
    "config5 = {\n",
    "        'with_representation': True, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 50, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'input_representation' : 0, # 예를 들면 (80, 20) 차원의 벡터 (80은 window_length에 따른 관측치 수, 20은 representation 특징벡터 차원 수)를 넣어야 함. 지금은 loader부분에서 random값들어가 있음\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 100 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b787f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x = pickle.load(open(os.path.join(data_dir, 'x_train - 복사본.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3675454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 561, 281)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e75961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.278419</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>0.276629</td>\n",
       "      <td>0.277199</td>\n",
       "      <td>0.279454</td>\n",
       "      <td>0.277432</td>\n",
       "      <td>0.277293</td>\n",
       "      <td>0.280586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398249</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>0.240039</td>\n",
       "      <td>0.278460</td>\n",
       "      <td>0.266821</td>\n",
       "      <td>0.286568</td>\n",
       "      <td>0.305840</td>\n",
       "      <td>0.310360</td>\n",
       "      <td>0.287725</td>\n",
       "      <td>0.220035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.010098</td>\n",
       "      <td>-0.019641</td>\n",
       "      <td>-0.030488</td>\n",
       "      <td>-0.021751</td>\n",
       "      <td>-0.009960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027318</td>\n",
       "      <td>-0.023303</td>\n",
       "      <td>-0.017442</td>\n",
       "      <td>-0.023398</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>-0.054635</td>\n",
       "      <td>-0.038922</td>\n",
       "      <td>-0.007873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.110022</td>\n",
       "      <td>-0.125360</td>\n",
       "      <td>-0.120751</td>\n",
       "      <td>-0.106065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062956</td>\n",
       "      <td>-0.081836</td>\n",
       "      <td>-0.085923</td>\n",
       "      <td>-0.130455</td>\n",
       "      <td>-0.129805</td>\n",
       "      <td>-0.092536</td>\n",
       "      <td>-0.124971</td>\n",
       "      <td>-0.139121</td>\n",
       "      <td>-0.121019</td>\n",
       "      <td>-0.105861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.997335</td>\n",
       "      <td>-0.996921</td>\n",
       "      <td>-0.996559</td>\n",
       "      <td>-0.997328</td>\n",
       "      <td>-0.994803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285904</td>\n",
       "      <td>-0.269353</td>\n",
       "      <td>-0.271956</td>\n",
       "      <td>-0.277102</td>\n",
       "      <td>-0.332375</td>\n",
       "      <td>-0.358399</td>\n",
       "      <td>-0.309300</td>\n",
       "      <td>-0.299196</td>\n",
       "      <td>-0.345199</td>\n",
       "      <td>-0.325851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990487</td>\n",
       "      <td>-0.967186</td>\n",
       "      <td>-0.966728</td>\n",
       "      <td>-0.961245</td>\n",
       "      <td>-0.972758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162323</td>\n",
       "      <td>0.267064</td>\n",
       "      <td>0.166483</td>\n",
       "      <td>0.122801</td>\n",
       "      <td>0.188234</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.191434</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>0.065631</td>\n",
       "      <td>0.069517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>0.014637</td>\n",
       "      <td>-0.561871</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>-0.482871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677174</td>\n",
       "      <td>0.774611</td>\n",
       "      <td>0.293660</td>\n",
       "      <td>-0.186212</td>\n",
       "      <td>-0.309551</td>\n",
       "      <td>-0.886370</td>\n",
       "      <td>-0.208520</td>\n",
       "      <td>0.323233</td>\n",
       "      <td>0.196858</td>\n",
       "      <td>0.445547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-0.018446</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.189512</td>\n",
       "      <td>0.467383</td>\n",
       "      <td>0.117797</td>\n",
       "      <td>-0.070670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105358</td>\n",
       "      <td>0.085763</td>\n",
       "      <td>-0.116361</td>\n",
       "      <td>-0.283945</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>0.500656</td>\n",
       "      <td>0.072863</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.435944</td>\n",
       "      <td>-0.740208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-0.841247</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>-0.849632</td>\n",
       "      <td>-0.852150</td>\n",
       "      <td>-0.851017</td>\n",
       "      <td>-0.847971</td>\n",
       "      <td>-0.848294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656642</td>\n",
       "      <td>-0.673466</td>\n",
       "      <td>-0.681290</td>\n",
       "      <td>-0.696572</td>\n",
       "      <td>-0.694272</td>\n",
       "      <td>-0.687830</td>\n",
       "      <td>-0.700868</td>\n",
       "      <td>-0.711755</td>\n",
       "      <td>-0.705702</td>\n",
       "      <td>-0.697422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.179941</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.184823</td>\n",
       "      <td>0.182170</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.190310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317010</td>\n",
       "      <td>0.305444</td>\n",
       "      <td>0.300935</td>\n",
       "      <td>0.292482</td>\n",
       "      <td>0.294402</td>\n",
       "      <td>0.299898</td>\n",
       "      <td>0.292534</td>\n",
       "      <td>0.285024</td>\n",
       "      <td>0.289208</td>\n",
       "      <td>0.294479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-0.058627</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>-0.042126</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>-0.037364</td>\n",
       "      <td>-0.034417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110095</td>\n",
       "      <td>0.107938</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.097767</td>\n",
       "      <td>0.097192</td>\n",
       "      <td>0.095160</td>\n",
       "      <td>0.089194</td>\n",
       "      <td>0.087985</td>\n",
       "      <td>0.088638</td>\n",
       "      <td>0.090792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.288585  0.278419  0.279653  0.279174  0.276629  0.277199  0.279454   \n",
       "1   -0.020294 -0.016411 -0.019467 -0.026201 -0.016570 -0.010098 -0.019641   \n",
       "2   -0.132905 -0.123520 -0.113462 -0.123283 -0.115362 -0.105137 -0.110022   \n",
       "3   -0.995279 -0.998245 -0.995380 -0.996091 -0.998139 -0.997335 -0.996921   \n",
       "4   -0.983111 -0.975300 -0.967187 -0.983403 -0.980817 -0.990487 -0.967186   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "556 -0.464761 -0.732626  0.100699  0.640011  0.693578  0.275041  0.014637   \n",
       "557 -0.018446  0.703511  0.808529 -0.485366 -0.615971 -0.368224 -0.189512   \n",
       "558 -0.841247 -0.844788 -0.848933 -0.848649 -0.847865 -0.849632 -0.852150   \n",
       "559  0.179941  0.180289  0.180637  0.181935  0.185151  0.184823  0.182170   \n",
       "560 -0.058627 -0.054317 -0.049118 -0.047663 -0.043892 -0.042126 -0.043010   \n",
       "\n",
       "          7         8         9    ...       271       272       273  \\\n",
       "0    0.277432  0.277293  0.280586  ...  0.398249  0.328590  0.240039   \n",
       "1   -0.030488 -0.021751 -0.009960  ...  0.027318 -0.023303 -0.017442   \n",
       "2   -0.125360 -0.120751 -0.106065  ... -0.062956 -0.081836 -0.085923   \n",
       "3   -0.996559 -0.997328 -0.994803  ... -0.285904 -0.269353 -0.271956   \n",
       "4   -0.966728 -0.961245 -0.972758  ...  0.162323  0.267064  0.166483   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "556 -0.561871 -0.234313 -0.482871  ...  0.677174  0.774611  0.293660   \n",
       "557  0.467383  0.117797 -0.070670  ... -0.105358  0.085763 -0.116361   \n",
       "558 -0.851017 -0.847971 -0.848294  ... -0.656642 -0.673466 -0.681290   \n",
       "559  0.183779  0.188982  0.190310  ...  0.317010  0.305444  0.300935   \n",
       "560 -0.041976 -0.037364 -0.034417  ...  0.110095  0.107938  0.104824   \n",
       "\n",
       "          274       275       276       277       278       279       280  \n",
       "0    0.278460  0.266821  0.286568  0.305840  0.310360  0.287725  0.220035  \n",
       "1   -0.023398 -0.018607  0.020619 -0.002192 -0.054635 -0.038922 -0.007873  \n",
       "2   -0.130455 -0.129805 -0.092536 -0.124971 -0.139121 -0.121019 -0.105861  \n",
       "3   -0.277102 -0.332375 -0.358399 -0.309300 -0.299196 -0.345199 -0.325851  \n",
       "4    0.122801  0.188234  0.184799  0.191434  0.131415  0.065631  0.069517  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "556 -0.186212 -0.309551 -0.886370 -0.208520  0.323233  0.196858  0.445547  \n",
       "557 -0.283945  0.178750  0.500656  0.072863  0.009463  0.435944 -0.740208  \n",
       "558 -0.696572 -0.694272 -0.687830 -0.700868 -0.711755 -0.705702 -0.697422  \n",
       "559  0.292482  0.294402  0.299898  0.292534  0.285024  0.289208  0.294479  \n",
       "560  0.097767  0.097192  0.095160  0.089194  0.087985  0.088638  0.090792  \n",
       "\n",
       "[561 rows x 281 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e84de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'X_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'X_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "# train_data = {'x' : train_x, 'y' : train_y}\n",
    "# test_data = {'x' : test_x, 'y' : test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73359cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance x input_dims x window_size) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a95ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364d8b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 9, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb318055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.004053</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.044729</td>\n",
       "      <td>0.043719</td>\n",
       "      <td>0.035379</td>\n",
       "      <td>0.031188</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.010068</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>-0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.044992</td>\n",
       "      <td>0.047686</td>\n",
       "      <td>0.046812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.018454</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>0.028818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.069174</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>-0.003434</td>\n",
       "      <td>-0.005051</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>-0.005166</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.022859</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>-0.002170</td>\n",
       "      <td>-0.005643</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.012817</td>\n",
       "      <td>1.022833</td>\n",
       "      <td>1.022028</td>\n",
       "      <td>1.017877</td>\n",
       "      <td>1.023680</td>\n",
       "      <td>1.016974</td>\n",
       "      <td>1.017746</td>\n",
       "      <td>1.019263</td>\n",
       "      <td>1.016417</td>\n",
       "      <td>1.020745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020981</td>\n",
       "      <td>1.018065</td>\n",
       "      <td>1.019638</td>\n",
       "      <td>1.020017</td>\n",
       "      <td>1.018766</td>\n",
       "      <td>1.019815</td>\n",
       "      <td>1.019290</td>\n",
       "      <td>1.018445</td>\n",
       "      <td>1.019372</td>\n",
       "      <td>1.021171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.123217</td>\n",
       "      <td>-0.126876</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>-0.124928</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>-0.124462</td>\n",
       "      <td>-0.127361</td>\n",
       "      <td>-0.127891</td>\n",
       "      <td>-0.125868</td>\n",
       "      <td>-0.124368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123493</td>\n",
       "      <td>-0.121995</td>\n",
       "      <td>-0.123910</td>\n",
       "      <td>-0.127970</td>\n",
       "      <td>-0.128295</td>\n",
       "      <td>-0.127010</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>-0.124070</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>-0.121326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.105687</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>0.102814</td>\n",
       "      <td>0.107493</td>\n",
       "      <td>0.109386</td>\n",
       "      <td>0.103886</td>\n",
       "      <td>0.102473</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.093177</td>\n",
       "      <td>0.088742</td>\n",
       "      <td>0.090505</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.098350</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.094987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000181  0.010139  0.009276  0.005066  0.010810  0.004045  0.004757   \n",
       "1  0.010767  0.006579  0.008929  0.007489  0.006141  0.006944  0.003552   \n",
       "2  0.055561  0.055125  0.048405  0.049775  0.043013  0.044729  0.043719   \n",
       "3  0.030191  0.043711  0.035688  0.040402  0.047097  0.050185  0.050545   \n",
       "4  0.066014  0.042699  0.074850  0.057320  0.052343  0.069174  0.049867   \n",
       "5  0.022859  0.010316  0.013250  0.017751  0.002553  0.007725  0.004325   \n",
       "6  1.012817  1.022833  1.022028  1.017877  1.023680  1.016974  1.017746   \n",
       "7 -0.123217 -0.126876 -0.124004 -0.124928 -0.125767 -0.124462 -0.127361   \n",
       "8  0.102934  0.105687  0.102102  0.106553  0.102814  0.107493  0.109386   \n",
       "\n",
       "        7         8         9    ...       118       119       120       121  \\\n",
       "0  0.006214  0.003307  0.007572  ...  0.001412 -0.001509  0.000060  0.000435   \n",
       "1  0.002537  0.004085  0.005118  ...  0.000172  0.001756 -0.000076 -0.004053   \n",
       "2  0.035379  0.031188  0.023567  ...  0.000339 -0.000842 -0.005926 -0.010068   \n",
       "3  0.044992  0.047686  0.046812  ...  0.012667  0.010475  0.011098  0.013411   \n",
       "4  0.056751  0.058189  0.043199  ... -0.002878 -0.002945 -0.003434 -0.005051   \n",
       "5  0.010617  0.017189  0.010511  ... -0.006042 -0.006891 -0.004903  0.001354   \n",
       "6  1.019263  1.016417  1.020745  ...  1.020981  1.018065  1.019638  1.020017   \n",
       "7 -0.127891 -0.125868 -0.124368  ... -0.123493 -0.121995 -0.123910 -0.127970   \n",
       "8  0.103886  0.102473  0.097566  ...  0.100058  0.098564  0.093177  0.088742   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0 -0.000819  0.000228 -0.000300 -0.001147 -0.000222  0.001576  \n",
       "1 -0.004295 -0.002929 -0.002023  0.000171  0.001574  0.003070  \n",
       "2 -0.008023 -0.003412  0.000359  0.002648  0.002381 -0.002270  \n",
       "3  0.018454  0.025197  0.032328  0.039852  0.037449  0.028818  \n",
       "4 -0.004988 -0.005166 -0.001298  0.001909 -0.000080 -0.000038  \n",
       "5  0.008033  0.007355  0.002669 -0.002170 -0.005643 -0.001446  \n",
       "6  1.018766  1.019815  1.019290  1.018445  1.019372  1.021171  \n",
       "7 -0.128295 -0.127010 -0.126185 -0.124070 -0.122745 -0.121326  \n",
       "8  0.090505  0.094843  0.098350  0.100385  0.099874  0.094987  \n",
       "\n",
       "[9 rows x 128 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfb297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121306af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'x_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'state_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'x_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'state_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564b0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 1.7534 Acc: 0.1250\n",
      "val Loss: 1.6363 Acc: 0.2400\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 1.6556 Acc: 0.2125\n",
      "val Loss: 1.5519 Acc: 0.4400\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 1.5757 Acc: 0.4125\n",
      "val Loss: 1.4809 Acc: 0.5200\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 1.5100 Acc: 0.4250\n",
      "val Loss: 1.4213 Acc: 0.5200\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 1.4546 Acc: 0.4375\n",
      "val Loss: 1.3730 Acc: 0.5200\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 1.4105 Acc: 0.4125\n",
      "val Loss: 1.3356 Acc: 0.5200\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 1.3754 Acc: 0.4250\n",
      "val Loss: 1.3068 Acc: 0.5200\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 1.3448 Acc: 0.4250\n",
      "val Loss: 1.2837 Acc: 0.5200\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 1.3204 Acc: 0.4250\n",
      "val Loss: 1.2664 Acc: 0.5200\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 1.2967 Acc: 0.4500\n",
      "val Loss: 1.2545 Acc: 0.5200\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 1.2747 Acc: 0.4625\n",
      "val Loss: 1.2456 Acc: 0.5200\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 1.2561 Acc: 0.5000\n",
      "val Loss: 1.2390 Acc: 0.5200\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 1.2381 Acc: 0.4875\n",
      "val Loss: 1.2316 Acc: 0.5200\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 1.2226 Acc: 0.5125\n",
      "val Loss: 1.2245 Acc: 0.5200\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 1.2079 Acc: 0.5625\n",
      "val Loss: 1.2182 Acc: 0.5600\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 1.1942 Acc: 0.5750\n",
      "val Loss: 1.2147 Acc: 0.5600\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 1.1826 Acc: 0.5625\n",
      "val Loss: 1.2116 Acc: 0.5600\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 1.1719 Acc: 0.5500\n",
      "val Loss: 1.2071 Acc: 0.5600\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 1.1615 Acc: 0.5500\n",
      "val Loss: 1.2000 Acc: 0.5600\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 1.1509 Acc: 0.5625\n",
      "val Loss: 1.1902 Acc: 0.6400\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 1.1411 Acc: 0.5625\n",
      "val Loss: 1.1784 Acc: 0.6800\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 1.1309 Acc: 0.5625\n",
      "val Loss: 1.1655 Acc: 0.6800\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 1.1203 Acc: 0.5750\n",
      "val Loss: 1.1475 Acc: 0.6800\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 1.1117 Acc: 0.5875\n",
      "val Loss: 1.1304 Acc: 0.6400\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 1.1054 Acc: 0.5625\n",
      "val Loss: 1.1187 Acc: 0.6400\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 1.0974 Acc: 0.5750\n",
      "val Loss: 1.1147 Acc: 0.6400\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 1.0905 Acc: 0.5750\n",
      "val Loss: 1.1129 Acc: 0.6400\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 1.0825 Acc: 0.5875\n",
      "val Loss: 1.1088 Acc: 0.6400\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 1.0761 Acc: 0.5875\n",
      "val Loss: 1.1087 Acc: 0.6400\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 1.0690 Acc: 0.5875\n",
      "val Loss: 1.1112 Acc: 0.6400\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 1.0628 Acc: 0.6125\n",
      "val Loss: 1.1112 Acc: 0.6400\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 1.0564 Acc: 0.6125\n",
      "val Loss: 1.1067 Acc: 0.6400\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 1.0500 Acc: 0.6125\n",
      "val Loss: 1.1005 Acc: 0.6400\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 1.0442 Acc: 0.6125\n",
      "val Loss: 1.0945 Acc: 0.6400\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 1.0382 Acc: 0.6000\n",
      "val Loss: 1.0910 Acc: 0.6400\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 1.0328 Acc: 0.5750\n",
      "val Loss: 1.0885 Acc: 0.6400\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 1.0264 Acc: 0.5750\n",
      "val Loss: 1.0841 Acc: 0.6400\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 1.0208 Acc: 0.5750\n",
      "val Loss: 1.0791 Acc: 0.6400\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 1.0154 Acc: 0.5750\n",
      "val Loss: 1.0760 Acc: 0.6400\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 1.0106 Acc: 0.5750\n",
      "val Loss: 1.0727 Acc: 0.6400\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 1.0054 Acc: 0.6000\n",
      "val Loss: 1.0715 Acc: 0.6400\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 1.0000 Acc: 0.6000\n",
      "val Loss: 1.0739 Acc: 0.6400\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.9932 Acc: 0.6125\n",
      "val Loss: 1.0761 Acc: 0.6400\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.9878 Acc: 0.6125\n",
      "val Loss: 1.0795 Acc: 0.6400\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.9811 Acc: 0.6250\n",
      "val Loss: 1.0751 Acc: 0.6400\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.9743 Acc: 0.6375\n",
      "val Loss: 1.0657 Acc: 0.6400\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.9682 Acc: 0.6500\n",
      "val Loss: 1.0565 Acc: 0.6400\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.9636 Acc: 0.6500\n",
      "val Loss: 1.0484 Acc: 0.6400\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.9606 Acc: 0.6250\n",
      "val Loss: 1.0431 Acc: 0.6400\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.9562 Acc: 0.6250\n",
      "val Loss: 1.0421 Acc: 0.6400\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.9515 Acc: 0.6625\n",
      "val Loss: 1.0432 Acc: 0.6400\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.9450 Acc: 0.6875\n",
      "val Loss: 1.0455 Acc: 0.6400\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.9387 Acc: 0.6875\n",
      "val Loss: 1.0506 Acc: 0.6400\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.9321 Acc: 0.6875\n",
      "val Loss: 1.0619 Acc: 0.6400\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.9297 Acc: 0.7125\n",
      "val Loss: 1.0713 Acc: 0.6400\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.9253 Acc: 0.7000\n",
      "val Loss: 1.0699 Acc: 0.6400\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.9197 Acc: 0.7000\n",
      "val Loss: 1.0605 Acc: 0.6400\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.9102 Acc: 0.7125\n",
      "val Loss: 1.0464 Acc: 0.6400\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.9047 Acc: 0.7125\n",
      "val Loss: 1.0327 Acc: 0.6400\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.8969 Acc: 0.7000\n",
      "val Loss: 1.0285 Acc: 0.6400\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.8909 Acc: 0.7000\n",
      "val Loss: 1.0296 Acc: 0.6400\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.8855 Acc: 0.7125\n",
      "val Loss: 1.0299 Acc: 0.6400\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.8794 Acc: 0.7250\n",
      "val Loss: 1.0260 Acc: 0.6400\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.8747 Acc: 0.7250\n",
      "val Loss: 1.0202 Acc: 0.6400\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.8687 Acc: 0.7250\n",
      "val Loss: 1.0147 Acc: 0.6400\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.8635 Acc: 0.7125\n",
      "val Loss: 1.0109 Acc: 0.6400\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.8574 Acc: 0.7375\n",
      "val Loss: 1.0094 Acc: 0.6400\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.8506 Acc: 0.7375\n",
      "val Loss: 1.0138 Acc: 0.6400\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.8437 Acc: 0.7375\n",
      "val Loss: 1.0195 Acc: 0.6400\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.8405 Acc: 0.7125\n",
      "val Loss: 1.0213 Acc: 0.6400\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.8338 Acc: 0.7250\n",
      "val Loss: 1.0189 Acc: 0.6400\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.8280 Acc: 0.7375\n",
      "val Loss: 1.0209 Acc: 0.6400\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.8229 Acc: 0.7375\n",
      "val Loss: 1.0177 Acc: 0.6400\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.8174 Acc: 0.7375\n",
      "val Loss: 1.0092 Acc: 0.6400\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.8102 Acc: 0.7500\n",
      "val Loss: 0.9974 Acc: 0.6400\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.8033 Acc: 0.7500\n",
      "val Loss: 0.9886 Acc: 0.6400\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.7969 Acc: 0.7500\n",
      "val Loss: 0.9826 Acc: 0.6400\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.7913 Acc: 0.7500\n",
      "val Loss: 0.9790 Acc: 0.6400\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.7849 Acc: 0.7500\n",
      "val Loss: 0.9830 Acc: 0.6400\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.7785 Acc: 0.7500\n",
      "val Loss: 0.9915 Acc: 0.6400\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.7734 Acc: 0.7500\n",
      "val Loss: 0.9952 Acc: 0.6800\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.7683 Acc: 0.7625\n",
      "val Loss: 0.9941 Acc: 0.6800\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.7643 Acc: 0.7625\n",
      "val Loss: 0.9866 Acc: 0.7200\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.7563 Acc: 0.7625\n",
      "val Loss: 0.9722 Acc: 0.6400\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.7482 Acc: 0.7500\n",
      "val Loss: 0.9564 Acc: 0.6800\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.7500\n",
      "val Loss: 0.9504 Acc: 0.6800\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.7363 Acc: 0.7625\n",
      "val Loss: 0.9524 Acc: 0.6800\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.7750\n",
      "val Loss: 0.9524 Acc: 0.6800\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.7247 Acc: 0.7750\n",
      "val Loss: 0.9523 Acc: 0.6800\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.7750\n",
      "val Loss: 0.9540 Acc: 0.6800\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.7152 Acc: 0.7625\n",
      "val Loss: 0.9508 Acc: 0.7200\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.7070 Acc: 0.7750\n",
      "val Loss: 0.9417 Acc: 0.6800\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.6989 Acc: 0.7750\n",
      "val Loss: 0.9365 Acc: 0.6800\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.7750\n",
      "val Loss: 0.9321 Acc: 0.6800\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.6859 Acc: 0.7750\n",
      "val Loss: 0.9363 Acc: 0.7200\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.6797 Acc: 0.7750\n",
      "val Loss: 0.9406 Acc: 0.6800\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.6746 Acc: 0.7750\n",
      "val Loss: 0.9440 Acc: 0.7200\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.6713 Acc: 0.8000\n",
      "val Loss: 0.9422 Acc: 0.7200\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.7875\n",
      "val Loss: 0.9344 Acc: 0.7200\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.7875\n",
      "val Loss: 0.9352 Acc: 0.7200\n",
      "\n",
      "Training complete in 0m 2s\n",
      "Best val Acc: 0.720000\n"
     ]
    }
   ],
   "source": [
    "# Case 1. w/o data representation & RNN\n",
    "config = config1\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "test_accuracy = data_classification.getResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefa80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 1.8122 Acc: 0.0125\n",
      "val Loss: 1.7687 Acc: 0.4800\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 1.7889 Acc: 0.3500\n",
      "val Loss: 1.7440 Acc: 0.6800\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 1.7664 Acc: 0.5125\n",
      "val Loss: 1.7192 Acc: 0.6400\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 1.7452 Acc: 0.5125\n",
      "val Loss: 1.6954 Acc: 0.6000\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 1.7235 Acc: 0.5125\n",
      "val Loss: 1.6731 Acc: 0.6000\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 1.7014 Acc: 0.5125\n",
      "val Loss: 1.6515 Acc: 0.6000\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 1.6814 Acc: 0.5000\n",
      "val Loss: 1.6300 Acc: 0.6000\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 1.6604 Acc: 0.5000\n",
      "val Loss: 1.6089 Acc: 0.6000\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 1.6393 Acc: 0.5000\n",
      "val Loss: 1.5880 Acc: 0.6000\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 1.6196 Acc: 0.5000\n",
      "val Loss: 1.5670 Acc: 0.6000\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 1.5990 Acc: 0.5000\n",
      "val Loss: 1.5464 Acc: 0.6000\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 1.5786 Acc: 0.5125\n",
      "val Loss: 1.5257 Acc: 0.6800\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 1.5579 Acc: 0.5250\n",
      "val Loss: 1.5048 Acc: 0.6800\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 1.5374 Acc: 0.5500\n",
      "val Loss: 1.4837 Acc: 0.6800\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 1.5165 Acc: 0.5500\n",
      "val Loss: 1.4626 Acc: 0.6800\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 1.4960 Acc: 0.5500\n",
      "val Loss: 1.4415 Acc: 0.6800\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 1.4755 Acc: 0.5500\n",
      "val Loss: 1.4205 Acc: 0.6800\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 1.4554 Acc: 0.5750\n",
      "val Loss: 1.3995 Acc: 0.6800\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 1.4337 Acc: 0.5750\n",
      "val Loss: 1.3781 Acc: 0.6800\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 1.4134 Acc: 0.5875\n",
      "val Loss: 1.3561 Acc: 0.6800\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 1.3924 Acc: 0.6125\n",
      "val Loss: 1.3347 Acc: 0.6800\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 1.3713 Acc: 0.6250\n",
      "val Loss: 1.3142 Acc: 0.6800\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 1.3502 Acc: 0.6250\n",
      "val Loss: 1.2940 Acc: 0.6800\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 1.3293 Acc: 0.6500\n",
      "val Loss: 1.2735 Acc: 0.6800\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 1.3091 Acc: 0.6625\n",
      "val Loss: 1.2526 Acc: 0.6800\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 1.2892 Acc: 0.6750\n",
      "val Loss: 1.2316 Acc: 0.7200\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 1.2696 Acc: 0.6625\n",
      "val Loss: 1.2111 Acc: 0.7200\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 1.2488 Acc: 0.6625\n",
      "val Loss: 1.1921 Acc: 0.7200\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 1.2294 Acc: 0.6625\n",
      "val Loss: 1.1736 Acc: 0.7600\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 1.2102 Acc: 0.6625\n",
      "val Loss: 1.1556 Acc: 0.7600\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 1.1905 Acc: 0.6750\n",
      "val Loss: 1.1370 Acc: 0.7600\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 1.1707 Acc: 0.6625\n",
      "val Loss: 1.1186 Acc: 0.7600\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 1.1509 Acc: 0.6625\n",
      "val Loss: 1.1003 Acc: 0.7600\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 1.1317 Acc: 0.6625\n",
      "val Loss: 1.0814 Acc: 0.7600\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 1.1119 Acc: 0.6625\n",
      "val Loss: 1.0623 Acc: 0.7600\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 1.0915 Acc: 0.6875\n",
      "val Loss: 1.0452 Acc: 0.7600\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 1.0711 Acc: 0.6750\n",
      "val Loss: 1.0285 Acc: 0.7600\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 1.0511 Acc: 0.6875\n",
      "val Loss: 1.0099 Acc: 0.7600\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 1.0291 Acc: 0.6875\n",
      "val Loss: 0.9871 Acc: 0.7600\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 1.0068 Acc: 0.6875\n",
      "val Loss: 0.9646 Acc: 0.7600\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.9812 Acc: 0.6875\n",
      "val Loss: 0.9456 Acc: 0.7600\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.9602 Acc: 0.6875\n",
      "val Loss: 0.9290 Acc: 0.7600\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.9398 Acc: 0.7000\n",
      "val Loss: 0.9134 Acc: 0.8000\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.9184 Acc: 0.7125\n",
      "val Loss: 0.8977 Acc: 0.8000\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.8991 Acc: 0.7625\n",
      "val Loss: 0.8800 Acc: 0.8000\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.8804 Acc: 0.7625\n",
      "val Loss: 0.8606 Acc: 0.8400\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.8631 Acc: 0.7625\n",
      "val Loss: 0.8462 Acc: 0.8400\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.8457 Acc: 0.7625\n",
      "val Loss: 0.8343 Acc: 0.8400\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.8287 Acc: 0.7750\n",
      "val Loss: 0.8242 Acc: 0.8400\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.8119 Acc: 0.7750\n",
      "val Loss: 0.8193 Acc: 0.8400\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.7965 Acc: 0.7750\n",
      "val Loss: 0.8127 Acc: 0.8400\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.7818 Acc: 0.7875\n",
      "val Loss: 0.8028 Acc: 0.8400\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.7750\n",
      "val Loss: 0.7847 Acc: 0.8400\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.7489 Acc: 0.7875\n",
      "val Loss: 0.7703 Acc: 0.8400\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.7341 Acc: 0.7875\n",
      "val Loss: 0.7595 Acc: 0.8400\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.7750\n",
      "val Loss: 0.7525 Acc: 0.8400\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.8000\n",
      "val Loss: 0.7517 Acc: 0.8400\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.8000\n",
      "val Loss: 0.7489 Acc: 0.8400\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.8000\n",
      "val Loss: 0.7367 Acc: 0.8400\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.6560 Acc: 0.8000\n",
      "val Loss: 0.7207 Acc: 0.8400\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.8000\n",
      "val Loss: 0.7095 Acc: 0.8400\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.8125\n",
      "val Loss: 0.7037 Acc: 0.8400\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.6173 Acc: 0.8125\n",
      "val Loss: 0.7041 Acc: 0.8800\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.6073 Acc: 0.8375\n",
      "val Loss: 0.7033 Acc: 0.8800\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.5962 Acc: 0.8875\n",
      "val Loss: 0.6950 Acc: 0.8800\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.5824 Acc: 0.9000\n",
      "val Loss: 0.6870 Acc: 0.8800\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.5702 Acc: 0.9000\n",
      "val Loss: 0.6784 Acc: 0.8800\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 0.9000\n",
      "val Loss: 0.6730 Acc: 0.8800\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.5506 Acc: 0.9000\n",
      "val Loss: 0.6686 Acc: 0.8800\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.5408 Acc: 0.8875\n",
      "val Loss: 0.6658 Acc: 0.8800\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.5299 Acc: 0.9125\n",
      "val Loss: 0.6655 Acc: 0.8800\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.5194 Acc: 0.9125\n",
      "val Loss: 0.6636 Acc: 0.8800\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.5120 Acc: 0.9250\n",
      "val Loss: 0.6645 Acc: 0.8400\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.5016 Acc: 0.9500\n",
      "val Loss: 0.6535 Acc: 0.8800\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.4903 Acc: 0.9500\n",
      "val Loss: 0.6349 Acc: 0.8800\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.4829 Acc: 0.9500\n",
      "val Loss: 0.6299 Acc: 0.8800\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.4772 Acc: 0.9500\n",
      "val Loss: 0.6296 Acc: 0.8800\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.4676 Acc: 0.9500\n",
      "val Loss: 0.6310 Acc: 0.8400\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.4574 Acc: 0.9500\n",
      "val Loss: 0.6304 Acc: 0.8400\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.4495 Acc: 0.9500\n",
      "val Loss: 0.6272 Acc: 0.8400\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.4403 Acc: 0.9500\n",
      "val Loss: 0.6236 Acc: 0.8400\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.4324 Acc: 0.9500\n",
      "val Loss: 0.6151 Acc: 0.8800\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.4238 Acc: 0.9500\n",
      "val Loss: 0.6053 Acc: 0.8800\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.4160 Acc: 0.9500\n",
      "val Loss: 0.6024 Acc: 0.8800\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.4078 Acc: 0.9625\n",
      "val Loss: 0.6012 Acc: 0.8800\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.4023 Acc: 0.9500\n",
      "val Loss: 0.6071 Acc: 0.8800\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.3952 Acc: 0.9500\n",
      "val Loss: 0.6128 Acc: 0.8400\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.3896 Acc: 0.9500\n",
      "val Loss: 0.6123 Acc: 0.8400\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.3814 Acc: 0.9625\n",
      "val Loss: 0.6100 Acc: 0.8400\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.3754 Acc: 0.9625\n",
      "val Loss: 0.6105 Acc: 0.8400\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.3682 Acc: 0.9625\n",
      "val Loss: 0.6097 Acc: 0.8400\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.3602 Acc: 0.9625\n",
      "val Loss: 0.6026 Acc: 0.8800\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.3534 Acc: 0.9625\n",
      "val Loss: 0.5932 Acc: 0.8800\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.3464 Acc: 0.9625\n",
      "val Loss: 0.5953 Acc: 0.8400\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.3403 Acc: 0.9625\n",
      "val Loss: 0.5942 Acc: 0.8400\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.3338 Acc: 0.9625\n",
      "val Loss: 0.6043 Acc: 0.8400\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.9625\n",
      "val Loss: 0.6087 Acc: 0.8400\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.3262 Acc: 0.9625\n",
      "val Loss: 0.6192 Acc: 0.8400\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.3248 Acc: 0.9625\n",
      "val Loss: 0.5989 Acc: 0.8400\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.3134 Acc: 0.9625\n",
      "val Loss: 0.5918 Acc: 0.8400\n",
      "\n",
      "Training complete in 0m 3s\n",
      "Best val Acc: 0.880000\n"
     ]
    }
   ],
   "source": [
    "# Case 2. w/o data representation & LSTM\n",
    "config = config2\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "test_accuracy = data_classification.getResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f7674f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 1.8700 Acc: 0.0000\n",
      "val Loss: 1.8108 Acc: 0.0400\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 1.8000 Acc: 0.1000\n",
      "val Loss: 1.7409 Acc: 0.2400\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 1.7355 Acc: 0.2875\n",
      "val Loss: 1.6773 Acc: 0.4800\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 1.6768 Acc: 0.4000\n",
      "val Loss: 1.6191 Acc: 0.5200\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 1.6251 Acc: 0.4125\n",
      "val Loss: 1.5679 Acc: 0.5200\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 1.5756 Acc: 0.4250\n",
      "val Loss: 1.5228 Acc: 0.5200\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 1.5337 Acc: 0.4250\n",
      "val Loss: 1.4808 Acc: 0.5200\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 1.4958 Acc: 0.4250\n",
      "val Loss: 1.4427 Acc: 0.5200\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 1.4605 Acc: 0.4250\n",
      "val Loss: 1.4082 Acc: 0.5200\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 1.4308 Acc: 0.4250\n",
      "val Loss: 1.3761 Acc: 0.5200\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 1.4047 Acc: 0.4250\n",
      "val Loss: 1.3470 Acc: 0.5200\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 1.3812 Acc: 0.4250\n",
      "val Loss: 1.3215 Acc: 0.5200\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 1.3618 Acc: 0.4250\n",
      "val Loss: 1.2997 Acc: 0.5200\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 1.3420 Acc: 0.4250\n",
      "val Loss: 1.2812 Acc: 0.5200\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 1.3263 Acc: 0.4250\n",
      "val Loss: 1.2648 Acc: 0.5200\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 1.3108 Acc: 0.4250\n",
      "val Loss: 1.2507 Acc: 0.5200\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 1.2971 Acc: 0.4250\n",
      "val Loss: 1.2381 Acc: 0.5200\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 1.2841 Acc: 0.4250\n",
      "val Loss: 1.2270 Acc: 0.5600\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 1.2713 Acc: 0.4375\n",
      "val Loss: 1.2172 Acc: 0.5600\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 1.2597 Acc: 0.4375\n",
      "val Loss: 1.2086 Acc: 0.5600\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 1.2475 Acc: 0.4750\n",
      "val Loss: 1.2005 Acc: 0.6000\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 1.2351 Acc: 0.4875\n",
      "val Loss: 1.1928 Acc: 0.6000\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 1.2230 Acc: 0.5000\n",
      "val Loss: 1.1859 Acc: 0.6400\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 1.2116 Acc: 0.5250\n",
      "val Loss: 1.1789 Acc: 0.6800\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 1.2012 Acc: 0.5375\n",
      "val Loss: 1.1729 Acc: 0.6800\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 1.1911 Acc: 0.5375\n",
      "val Loss: 1.1670 Acc: 0.6800\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 1.1816 Acc: 0.5500\n",
      "val Loss: 1.1607 Acc: 0.6800\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 1.1719 Acc: 0.5750\n",
      "val Loss: 1.1527 Acc: 0.6800\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 1.1622 Acc: 0.5750\n",
      "val Loss: 1.1422 Acc: 0.6800\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 1.1526 Acc: 0.5875\n",
      "val Loss: 1.1314 Acc: 0.6800\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 1.1430 Acc: 0.5875\n",
      "val Loss: 1.1202 Acc: 0.6800\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 1.1341 Acc: 0.5750\n",
      "val Loss: 1.1094 Acc: 0.6800\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 1.1251 Acc: 0.5750\n",
      "val Loss: 1.1000 Acc: 0.6800\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 1.1162 Acc: 0.5875\n",
      "val Loss: 1.0915 Acc: 0.6800\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 1.1068 Acc: 0.5875\n",
      "val Loss: 1.0845 Acc: 0.6800\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 1.0978 Acc: 0.5875\n",
      "val Loss: 1.0788 Acc: 0.6800\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 1.0889 Acc: 0.5875\n",
      "val Loss: 1.0739 Acc: 0.6800\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 1.0800 Acc: 0.6000\n",
      "val Loss: 1.0687 Acc: 0.6800\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 1.0714 Acc: 0.6375\n",
      "val Loss: 1.0623 Acc: 0.6800\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 1.0624 Acc: 0.6375\n",
      "val Loss: 1.0558 Acc: 0.7200\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 1.0538 Acc: 0.6375\n",
      "val Loss: 1.0502 Acc: 0.7200\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 1.0444 Acc: 0.6375\n",
      "val Loss: 1.0439 Acc: 0.7200\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 1.0360 Acc: 0.6375\n",
      "val Loss: 1.0373 Acc: 0.7200\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 1.0271 Acc: 0.6375\n",
      "val Loss: 1.0308 Acc: 0.7200\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 1.0180 Acc: 0.6375\n",
      "val Loss: 1.0238 Acc: 0.7200\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 1.0090 Acc: 0.6375\n",
      "val Loss: 1.0165 Acc: 0.7200\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 1.0003 Acc: 0.6375\n",
      "val Loss: 1.0084 Acc: 0.7200\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.9913 Acc: 0.6375\n",
      "val Loss: 0.9996 Acc: 0.7200\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.9829 Acc: 0.6375\n",
      "val Loss: 0.9905 Acc: 0.7200\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.9742 Acc: 0.6375\n",
      "val Loss: 0.9828 Acc: 0.7200\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.9653 Acc: 0.6375\n",
      "val Loss: 0.9749 Acc: 0.7200\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.9570 Acc: 0.6375\n",
      "val Loss: 0.9660 Acc: 0.7200\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.9492 Acc: 0.6375\n",
      "val Loss: 0.9570 Acc: 0.7200\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.9422 Acc: 0.6375\n",
      "val Loss: 0.9495 Acc: 0.7200\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.9324 Acc: 0.6375\n",
      "val Loss: 0.9459 Acc: 0.7200\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.9233 Acc: 0.6375\n",
      "val Loss: 0.9422 Acc: 0.7200\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.9141 Acc: 0.6500\n",
      "val Loss: 0.9392 Acc: 0.7200\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.9052 Acc: 0.6500\n",
      "val Loss: 0.9379 Acc: 0.7200\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.8962 Acc: 0.6625\n",
      "val Loss: 0.9363 Acc: 0.7600\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.8880 Acc: 0.6750\n",
      "val Loss: 0.9349 Acc: 0.7600\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.8800 Acc: 0.7000\n",
      "val Loss: 0.9321 Acc: 0.7600\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.8722 Acc: 0.7000\n",
      "val Loss: 0.9245 Acc: 0.7600\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.8638 Acc: 0.7000\n",
      "val Loss: 0.9143 Acc: 0.7600\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.8550 Acc: 0.7000\n",
      "val Loss: 0.9069 Acc: 0.7600\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.8468 Acc: 0.7000\n",
      "val Loss: 0.9003 Acc: 0.7600\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.8383 Acc: 0.7000\n",
      "val Loss: 0.8935 Acc: 0.7600\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.8295 Acc: 0.7000\n",
      "val Loss: 0.8896 Acc: 0.7600\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.8218 Acc: 0.7000\n",
      "val Loss: 0.8855 Acc: 0.7600\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.8133 Acc: 0.7000\n",
      "val Loss: 0.8779 Acc: 0.7600\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.8047 Acc: 0.7000\n",
      "val Loss: 0.8683 Acc: 0.7600\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.7963 Acc: 0.7000\n",
      "val Loss: 0.8590 Acc: 0.7600\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.7891 Acc: 0.7000\n",
      "val Loss: 0.8499 Acc: 0.7600\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.7822 Acc: 0.6875\n",
      "val Loss: 0.8399 Acc: 0.7200\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.7752 Acc: 0.6750\n",
      "val Loss: 0.8296 Acc: 0.7200\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.7682 Acc: 0.6750\n",
      "val Loss: 0.8193 Acc: 0.7200\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.7608 Acc: 0.7000\n",
      "val Loss: 0.8116 Acc: 0.7200\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.7533 Acc: 0.7125\n",
      "val Loss: 0.8078 Acc: 0.7600\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.7250\n",
      "val Loss: 0.8086 Acc: 0.7600\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.7352 Acc: 0.7375\n",
      "val Loss: 0.8102 Acc: 0.7600\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.7272 Acc: 0.7625\n",
      "val Loss: 0.8094 Acc: 0.7600\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.7875\n",
      "val Loss: 0.8072 Acc: 0.7600\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8000\n",
      "val Loss: 0.8033 Acc: 0.7600\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8000\n",
      "val Loss: 0.7943 Acc: 0.7600\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.6955 Acc: 0.7875\n",
      "val Loss: 0.7857 Acc: 0.7600\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.7750\n",
      "val Loss: 0.7786 Acc: 0.7600\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.7750\n",
      "val Loss: 0.7716 Acc: 0.7600\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.6750 Acc: 0.7750\n",
      "val Loss: 0.7688 Acc: 0.7600\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8000\n",
      "val Loss: 0.7678 Acc: 0.8000\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.8000\n",
      "val Loss: 0.7648 Acc: 0.8000\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8125\n",
      "val Loss: 0.7619 Acc: 0.8000\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.8250\n",
      "val Loss: 0.7581 Acc: 0.8000\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.8250\n",
      "val Loss: 0.7522 Acc: 0.8000\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.8250\n",
      "val Loss: 0.7475 Acc: 0.8400\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.6237 Acc: 0.8375\n",
      "val Loss: 0.7455 Acc: 0.8400\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.6179 Acc: 0.8375\n",
      "val Loss: 0.7404 Acc: 0.8400\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.6114 Acc: 0.8375\n",
      "val Loss: 0.7320 Acc: 0.8400\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.6044 Acc: 0.8375\n",
      "val Loss: 0.7232 Acc: 0.8000\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.5993 Acc: 0.8250\n",
      "val Loss: 0.7156 Acc: 0.8000\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.5940 Acc: 0.8250\n",
      "val Loss: 0.7096 Acc: 0.8000\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.5886 Acc: 0.8250\n",
      "val Loss: 0.7043 Acc: 0.8000\n",
      "\n",
      "Training complete in 0m 3s\n",
      "Best val Acc: 0.840000\n"
     ]
    }
   ],
   "source": [
    "# Case 3. w/o data representation & GRU\n",
    "config = config3\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "test_accuracy = data_classification.getResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59275e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 1.7814 Acc: 0.2500\n",
      "val Loss: 1.7544 Acc: 0.1200\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 1.7095 Acc: 0.2875\n",
      "val Loss: 1.6926 Acc: 0.1200\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 1.6575 Acc: 0.3125\n",
      "val Loss: 1.6356 Acc: 0.1200\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 1.5843 Acc: 0.3875\n",
      "val Loss: 1.5825 Acc: 0.2400\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 1.5424 Acc: 0.4125\n",
      "val Loss: 1.5268 Acc: 0.5600\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 1.4902 Acc: 0.3500\n",
      "val Loss: 1.4675 Acc: 0.5600\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 1.4291 Acc: 0.4625\n",
      "val Loss: 1.4075 Acc: 0.5600\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 1.3764 Acc: 0.4375\n",
      "val Loss: 1.3494 Acc: 0.5200\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 1.3315 Acc: 0.4250\n",
      "val Loss: 1.3014 Acc: 0.5200\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 1.2848 Acc: 0.4250\n",
      "val Loss: 1.2664 Acc: 0.5200\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 1.2473 Acc: 0.4125\n",
      "val Loss: 1.2448 Acc: 0.5200\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 1.1952 Acc: 0.4375\n",
      "val Loss: 1.2327 Acc: 0.5600\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 1.1746 Acc: 0.4375\n",
      "val Loss: 1.2233 Acc: 0.5600\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 1.1511 Acc: 0.4375\n",
      "val Loss: 1.2144 Acc: 0.5600\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 1.1059 Acc: 0.4750\n",
      "val Loss: 1.1966 Acc: 0.5600\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 1.1005 Acc: 0.4750\n",
      "val Loss: 1.1722 Acc: 0.6000\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 1.0547 Acc: 0.5375\n",
      "val Loss: 1.1375 Acc: 0.6800\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 1.0266 Acc: 0.5500\n",
      "val Loss: 1.0986 Acc: 0.7200\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.9686 Acc: 0.6250\n",
      "val Loss: 1.0650 Acc: 0.7600\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 1.0055 Acc: 0.6000\n",
      "val Loss: 1.0418 Acc: 0.7600\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.9525 Acc: 0.6125\n",
      "val Loss: 1.0239 Acc: 0.7600\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.9215 Acc: 0.6125\n",
      "val Loss: 1.0064 Acc: 0.7600\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.8703 Acc: 0.6750\n",
      "val Loss: 0.9906 Acc: 0.8000\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.8966 Acc: 0.6750\n",
      "val Loss: 0.9791 Acc: 0.8400\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.8075 Acc: 0.7125\n",
      "val Loss: 0.9681 Acc: 0.8400\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.8287 Acc: 0.6750\n",
      "val Loss: 0.9544 Acc: 0.8400\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.7315 Acc: 0.7500\n",
      "val Loss: 0.9367 Acc: 0.8400\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.7618 Acc: 0.7250\n",
      "val Loss: 0.9086 Acc: 0.8400\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.7375\n",
      "val Loss: 0.8807 Acc: 0.8400\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.7250\n",
      "val Loss: 0.8595 Acc: 0.8400\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.7250\n",
      "val Loss: 0.8472 Acc: 0.8400\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.7500\n",
      "val Loss: 0.8401 Acc: 0.8400\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.7250\n",
      "val Loss: 0.8373 Acc: 0.8400\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.6038 Acc: 0.7750\n",
      "val Loss: 0.8381 Acc: 0.8400\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.6203 Acc: 0.8000\n",
      "val Loss: 0.8407 Acc: 0.8000\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.5861 Acc: 0.8250\n",
      "val Loss: 0.8375 Acc: 0.8000\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.5285 Acc: 0.8375\n",
      "val Loss: 0.8369 Acc: 0.8000\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.5963 Acc: 0.7625\n",
      "val Loss: 0.8282 Acc: 0.8000\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.5359 Acc: 0.8750\n",
      "val Loss: 0.8125 Acc: 0.8000\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.5681 Acc: 0.8125\n",
      "val Loss: 0.7947 Acc: 0.8000\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.5031 Acc: 0.8375\n",
      "val Loss: 0.7839 Acc: 0.8000\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.4869 Acc: 0.8250\n",
      "val Loss: 0.7823 Acc: 0.8000\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.4634 Acc: 0.8375\n",
      "val Loss: 0.7855 Acc: 0.8000\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.4354 Acc: 0.8875\n",
      "val Loss: 0.7939 Acc: 0.8000\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 0.8500\n",
      "val Loss: 0.7918 Acc: 0.8000\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.4593 Acc: 0.8375\n",
      "val Loss: 0.7797 Acc: 0.8000\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.4643 Acc: 0.8250\n",
      "val Loss: 0.7757 Acc: 0.8000\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.4079 Acc: 0.8625\n",
      "val Loss: 0.7812 Acc: 0.8000\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.3943 Acc: 0.8875\n",
      "val Loss: 0.7905 Acc: 0.8000\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.3727 Acc: 0.8625\n",
      "val Loss: 0.7968 Acc: 0.8000\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.3981 Acc: 0.8750\n",
      "val Loss: 0.7917 Acc: 0.8400\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.3591 Acc: 0.8875\n",
      "val Loss: 0.7841 Acc: 0.8400\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.3625 Acc: 0.9125\n",
      "val Loss: 0.7801 Acc: 0.8400\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.3609 Acc: 0.9125\n",
      "val Loss: 0.7701 Acc: 0.8400\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.3463 Acc: 0.8875\n",
      "val Loss: 0.7605 Acc: 0.8400\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.3493 Acc: 0.9000\n",
      "val Loss: 0.7577 Acc: 0.8400\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.3265 Acc: 0.9125\n",
      "val Loss: 0.7566 Acc: 0.8800\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.3435 Acc: 0.8875\n",
      "val Loss: 0.7578 Acc: 0.8800\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.3669 Acc: 0.8875\n",
      "val Loss: 0.7645 Acc: 0.8400\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.3273 Acc: 0.9125\n",
      "val Loss: 0.7840 Acc: 0.8400\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.3426 Acc: 0.8750\n",
      "val Loss: 0.8067 Acc: 0.8400\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.3657 Acc: 0.8375\n",
      "val Loss: 0.8207 Acc: 0.8400\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.3534 Acc: 0.8750\n",
      "val Loss: 0.8120 Acc: 0.8400\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.3279 Acc: 0.8875\n",
      "val Loss: 0.7975 Acc: 0.8400\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.3115 Acc: 0.8750\n",
      "val Loss: 0.7846 Acc: 0.8400\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.3406 Acc: 0.8875\n",
      "val Loss: 0.7794 Acc: 0.8800\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.2742 Acc: 0.9125\n",
      "val Loss: 0.7788 Acc: 0.8800\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.3455 Acc: 0.9125\n",
      "val Loss: 0.7787 Acc: 0.8800\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.2889 Acc: 0.9000\n",
      "val Loss: 0.7809 Acc: 0.8800\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.3331 Acc: 0.8750\n",
      "val Loss: 0.7836 Acc: 0.8400\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.2541 Acc: 0.9250\n",
      "val Loss: 0.7892 Acc: 0.8400\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.2779 Acc: 0.9375\n",
      "val Loss: 0.8043 Acc: 0.8400\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.2961 Acc: 0.8875\n",
      "val Loss: 0.8153 Acc: 0.8400\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.3627 Acc: 0.8500\n",
      "val Loss: 0.8090 Acc: 0.8400\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.2507 Acc: 0.9125\n",
      "val Loss: 0.8021 Acc: 0.8400\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.3136 Acc: 0.9375\n",
      "val Loss: 0.8040 Acc: 0.8400\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.2491 Acc: 0.9000\n",
      "val Loss: 0.8048 Acc: 0.8400\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.2439 Acc: 0.9250\n",
      "val Loss: 0.8121 Acc: 0.8400\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.2510 Acc: 0.9250\n",
      "val Loss: 0.8242 Acc: 0.8400\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.2735 Acc: 0.8750\n",
      "val Loss: 0.8291 Acc: 0.8400\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.2752 Acc: 0.8875\n",
      "val Loss: 0.8264 Acc: 0.8400\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.2417 Acc: 0.9125\n",
      "val Loss: 0.8152 Acc: 0.8400\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.3116 Acc: 0.8875\n",
      "val Loss: 0.8101 Acc: 0.8400\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.9125\n",
      "val Loss: 0.8120 Acc: 0.8400\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.3033 Acc: 0.8875\n",
      "val Loss: 0.8191 Acc: 0.8400\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.2856 Acc: 0.9125\n",
      "val Loss: 0.8288 Acc: 0.8400\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.2603 Acc: 0.9000\n",
      "val Loss: 0.8286 Acc: 0.8400\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.2509 Acc: 0.8875\n",
      "val Loss: 0.8236 Acc: 0.8400\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.2776 Acc: 0.8875\n",
      "val Loss: 0.8200 Acc: 0.8400\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.2666 Acc: 0.8875\n",
      "val Loss: 0.8220 Acc: 0.8400\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.2713 Acc: 0.8875\n",
      "val Loss: 0.8303 Acc: 0.8400\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.2128 Acc: 0.9375\n",
      "val Loss: 0.8388 Acc: 0.8400\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.2473 Acc: 0.9250\n",
      "val Loss: 0.8399 Acc: 0.8400\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.2295 Acc: 0.9250\n",
      "val Loss: 0.8353 Acc: 0.8400\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.2836 Acc: 0.9125\n",
      "val Loss: 0.8297 Acc: 0.8400\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.2532 Acc: 0.9375\n",
      "val Loss: 0.8283 Acc: 0.8800\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.2433 Acc: 0.9125\n",
      "val Loss: 0.8316 Acc: 0.8800\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.2467 Acc: 0.9125\n",
      "val Loss: 0.8372 Acc: 0.8800\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.2457 Acc: 0.9000\n",
      "val Loss: 0.8424 Acc: 0.8400\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.2676 Acc: 0.9125\n",
      "val Loss: 0.8508 Acc: 0.8400\n",
      "\n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 0.880000\n"
     ]
    }
   ],
   "source": [
    "# Case 4. w/o data representation & CNN_1D\n",
    "config = config4\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "test_accuracy = data_classification.getResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b370aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 1.7696 Acc: 0.2750\n",
      "val Loss: 1.8004 Acc: 0.2800\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 1.7765 Acc: 0.2625\n",
      "val Loss: 1.8002 Acc: 0.2800\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 1.7764 Acc: 0.2875\n",
      "val Loss: 1.7999 Acc: 0.2800\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 1.7738 Acc: 0.2250\n",
      "val Loss: 1.7997 Acc: 0.2800\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 1.7655 Acc: 0.2750\n",
      "val Loss: 1.7994 Acc: 0.2800\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 1.7693 Acc: 0.2500\n",
      "val Loss: 1.7991 Acc: 0.2800\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 1.7608 Acc: 0.2500\n",
      "val Loss: 1.7989 Acc: 0.2800\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 1.7650 Acc: 0.2750\n",
      "val Loss: 1.7987 Acc: 0.2800\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 1.7627 Acc: 0.3000\n",
      "val Loss: 1.7985 Acc: 0.2800\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 1.7691 Acc: 0.2500\n",
      "val Loss: 1.7982 Acc: 0.2800\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 1.7615 Acc: 0.2875\n",
      "val Loss: 1.7980 Acc: 0.2800\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 1.7613 Acc: 0.3250\n",
      "val Loss: 1.7978 Acc: 0.2800\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 1.7701 Acc: 0.2750\n",
      "val Loss: 1.7975 Acc: 0.2800\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 1.7641 Acc: 0.3000\n",
      "val Loss: 1.7973 Acc: 0.2400\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 1.7551 Acc: 0.3375\n",
      "val Loss: 1.7971 Acc: 0.2400\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 1.7593 Acc: 0.2750\n",
      "val Loss: 1.7969 Acc: 0.2400\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 1.7653 Acc: 0.3250\n",
      "val Loss: 1.7967 Acc: 0.2400\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 1.7569 Acc: 0.3250\n",
      "val Loss: 1.7965 Acc: 0.2400\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 1.7625 Acc: 0.2875\n",
      "val Loss: 1.7964 Acc: 0.2000\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 1.7508 Acc: 0.3000\n",
      "val Loss: 1.7962 Acc: 0.2400\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 1.7486 Acc: 0.3250\n",
      "val Loss: 1.7960 Acc: 0.2400\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 1.7524 Acc: 0.3250\n",
      "val Loss: 1.7957 Acc: 0.2400\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 1.7517 Acc: 0.3000\n",
      "val Loss: 1.7955 Acc: 0.2400\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 1.7488 Acc: 0.3250\n",
      "val Loss: 1.7953 Acc: 0.2400\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 1.7526 Acc: 0.2875\n",
      "val Loss: 1.7951 Acc: 0.2400\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 1.7491 Acc: 0.2875\n",
      "val Loss: 1.7949 Acc: 0.2400\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 1.7477 Acc: 0.3500\n",
      "val Loss: 1.7947 Acc: 0.2400\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 1.7495 Acc: 0.3375\n",
      "val Loss: 1.7945 Acc: 0.2400\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 1.7475 Acc: 0.3500\n",
      "val Loss: 1.7943 Acc: 0.2400\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 1.7547 Acc: 0.2750\n",
      "val Loss: 1.7941 Acc: 0.2800\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 1.7592 Acc: 0.2375\n",
      "val Loss: 1.7939 Acc: 0.2800\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 1.7547 Acc: 0.2875\n",
      "val Loss: 1.7937 Acc: 0.2800\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 1.7622 Acc: 0.2500\n",
      "val Loss: 1.7935 Acc: 0.2800\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 1.7493 Acc: 0.3125\n",
      "val Loss: 1.7933 Acc: 0.2800\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 1.7495 Acc: 0.2875\n",
      "val Loss: 1.7931 Acc: 0.2800\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 1.7464 Acc: 0.3125\n",
      "val Loss: 1.7929 Acc: 0.2800\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 1.7645 Acc: 0.2625\n",
      "val Loss: 1.7926 Acc: 0.2800\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 1.7553 Acc: 0.3125\n",
      "val Loss: 1.7924 Acc: 0.2800\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 1.7558 Acc: 0.2375\n",
      "val Loss: 1.7922 Acc: 0.2800\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 1.7497 Acc: 0.2875\n",
      "val Loss: 1.7920 Acc: 0.2800\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 1.7473 Acc: 0.2750\n",
      "val Loss: 1.7918 Acc: 0.2800\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 1.7460 Acc: 0.3125\n",
      "val Loss: 1.7916 Acc: 0.2800\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 1.7532 Acc: 0.2875\n",
      "val Loss: 1.7914 Acc: 0.2800\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 1.7378 Acc: 0.3500\n",
      "val Loss: 1.7912 Acc: 0.2800\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 1.7417 Acc: 0.2875\n",
      "val Loss: 1.7910 Acc: 0.2800\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 1.7418 Acc: 0.3125\n",
      "val Loss: 1.7909 Acc: 0.2800\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 1.7665 Acc: 0.2500\n",
      "val Loss: 1.7907 Acc: 0.2800\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 1.7385 Acc: 0.3500\n",
      "val Loss: 1.7904 Acc: 0.2800\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 1.7511 Acc: 0.2875\n",
      "val Loss: 1.7902 Acc: 0.2800\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 1.7310 Acc: 0.3500\n",
      "val Loss: 1.7900 Acc: 0.2800\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 1.7538 Acc: 0.2750\n",
      "val Loss: 1.7898 Acc: 0.2800\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 1.7497 Acc: 0.2875\n",
      "val Loss: 1.7895 Acc: 0.2800\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 1.7413 Acc: 0.3000\n",
      "val Loss: 1.7893 Acc: 0.2800\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 1.7468 Acc: 0.3125\n",
      "val Loss: 1.7892 Acc: 0.2400\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 1.7546 Acc: 0.2375\n",
      "val Loss: 1.7890 Acc: 0.2400\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 1.7457 Acc: 0.2875\n",
      "val Loss: 1.7888 Acc: 0.2400\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 1.7429 Acc: 0.3125\n",
      "val Loss: 1.7886 Acc: 0.2400\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 1.7396 Acc: 0.3125\n",
      "val Loss: 1.7883 Acc: 0.2400\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 1.7398 Acc: 0.3375\n",
      "val Loss: 1.7881 Acc: 0.2400\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 1.7429 Acc: 0.2750\n",
      "val Loss: 1.7879 Acc: 0.2400\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 1.7428 Acc: 0.2875\n",
      "val Loss: 1.7876 Acc: 0.2400\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 1.7564 Acc: 0.2625\n",
      "val Loss: 1.7874 Acc: 0.2400\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 1.7356 Acc: 0.3250\n",
      "val Loss: 1.7871 Acc: 0.2400\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 1.7484 Acc: 0.2875\n",
      "val Loss: 1.7869 Acc: 0.2400\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 1.7310 Acc: 0.2750\n",
      "val Loss: 1.7866 Acc: 0.2400\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 1.7590 Acc: 0.2375\n",
      "val Loss: 1.7865 Acc: 0.2400\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 1.7281 Acc: 0.2750\n",
      "val Loss: 1.7863 Acc: 0.2400\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 1.7554 Acc: 0.2875\n",
      "val Loss: 1.7862 Acc: 0.2400\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 1.7450 Acc: 0.2750\n",
      "val Loss: 1.7860 Acc: 0.2400\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 1.7383 Acc: 0.2750\n",
      "val Loss: 1.7859 Acc: 0.2400\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 1.7380 Acc: 0.2625\n",
      "val Loss: 1.7858 Acc: 0.2400\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 1.7231 Acc: 0.3125\n",
      "val Loss: 1.7857 Acc: 0.2400\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 1.7333 Acc: 0.2875\n",
      "val Loss: 1.7856 Acc: 0.2400\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 1.7254 Acc: 0.3250\n",
      "val Loss: 1.7854 Acc: 0.2400\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 1.7334 Acc: 0.3250\n",
      "val Loss: 1.7853 Acc: 0.2800\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 1.7282 Acc: 0.3375\n",
      "val Loss: 1.7852 Acc: 0.2800\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 1.7381 Acc: 0.2875\n",
      "val Loss: 1.7851 Acc: 0.2800\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 1.7311 Acc: 0.2875\n",
      "val Loss: 1.7850 Acc: 0.2800\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 1.7287 Acc: 0.3500\n",
      "val Loss: 1.7849 Acc: 0.2800\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 1.7356 Acc: 0.2875\n",
      "val Loss: 1.7847 Acc: 0.2800\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 1.7379 Acc: 0.2875\n",
      "val Loss: 1.7846 Acc: 0.2800\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 1.7262 Acc: 0.3375\n",
      "val Loss: 1.7845 Acc: 0.2800\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 1.7262 Acc: 0.3250\n",
      "val Loss: 1.7843 Acc: 0.2800\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 1.7286 Acc: 0.3000\n",
      "val Loss: 1.7841 Acc: 0.2800\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 1.7340 Acc: 0.2750\n",
      "val Loss: 1.7839 Acc: 0.2800\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 1.7062 Acc: 0.4125\n",
      "val Loss: 1.7836 Acc: 0.2800\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 1.7241 Acc: 0.3375\n",
      "val Loss: 1.7833 Acc: 0.2800\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 1.7251 Acc: 0.2750\n",
      "val Loss: 1.7830 Acc: 0.2800\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 1.7360 Acc: 0.2625\n",
      "val Loss: 1.7828 Acc: 0.2800\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 1.7231 Acc: 0.3125\n",
      "val Loss: 1.7825 Acc: 0.2800\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 1.7428 Acc: 0.2625\n",
      "val Loss: 1.7823 Acc: 0.2800\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 1.7262 Acc: 0.3375\n",
      "val Loss: 1.7821 Acc: 0.2800\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 1.7271 Acc: 0.2875\n",
      "val Loss: 1.7819 Acc: 0.2800\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 1.7177 Acc: 0.3375\n",
      "val Loss: 1.7817 Acc: 0.2800\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 1.7297 Acc: 0.2875\n",
      "val Loss: 1.7815 Acc: 0.2800\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 1.7089 Acc: 0.3625\n",
      "val Loss: 1.7812 Acc: 0.2800\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 1.7106 Acc: 0.3250\n",
      "val Loss: 1.7810 Acc: 0.2800\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 1.7262 Acc: 0.3125\n",
      "val Loss: 1.7808 Acc: 0.2800\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 1.7233 Acc: 0.2875\n",
      "val Loss: 1.7806 Acc: 0.2800\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 1.7293 Acc: 0.3000\n",
      "val Loss: 1.7804 Acc: 0.2800\n",
      "\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.280000\n"
     ]
    }
   ],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "test_accuracy = data_classification.getResult()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
