{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import main_classificaiton as mc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c4dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & RNN model \n",
    "config1 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'RNN', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation &LSTM model \n",
    "config2 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & GRU model \n",
    "config3 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & CNN_1D model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "# 특징 벡터의 사이즈 = 20 이라고 가정\n",
    "config5 = {\n",
    "        'with_representation': True, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'input_representation' : 0, # 예를 들면 (80, 20) 차원의 벡터 (80은 window_length에 따른 관측치 수, 20은 representation 특징벡터 차원 수)를 넣어야 함. 지금은 loader부분에서 random값들어가 있음\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'X_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'X_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance x input_dims x window_size) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564b0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6584 Acc: 0.3578\n",
      "val Loss: 1.4538 Acc: 0.3759\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0077 Acc: 0.5560\n",
      "val Loss: 1.0960 Acc: 0.5289\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9814 Acc: 0.5594\n",
      "val Loss: 1.0072 Acc: 0.5595\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.9413 Acc: 0.5902\n",
      "val Loss: 0.9829 Acc: 0.5887\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.9057 Acc: 0.6235\n",
      "val Loss: 0.9704 Acc: 0.6159\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.6936 Acc: 0.7210\n",
      "val Loss: 0.7325 Acc: 0.7410\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5424 Acc: 0.7854\n",
      "val Loss: 0.5766 Acc: 0.7954\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4317 Acc: 0.8369\n",
      "val Loss: 0.4270 Acc: 0.8402\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3776 Acc: 0.8636\n",
      "val Loss: 0.4722 Acc: 0.8600\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3262 Acc: 0.8919\n",
      "val Loss: 0.4379 Acc: 0.8702\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2836 Acc: 0.9102\n",
      "val Loss: 0.4246 Acc: 0.8872\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2483 Acc: 0.9182\n",
      "val Loss: 0.3875 Acc: 0.9021\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2417 Acc: 0.9197\n",
      "val Loss: 0.3927 Acc: 0.9035\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2165 Acc: 0.9264\n",
      "val Loss: 0.3325 Acc: 0.8817\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1973 Acc: 0.9362\n",
      "val Loss: 0.2994 Acc: 0.9191\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1923 Acc: 0.9374\n",
      "val Loss: 0.2696 Acc: 0.9157\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1789 Acc: 0.9396\n",
      "val Loss: 0.2829 Acc: 0.8973\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.2746 Acc: 0.9077\n",
      "val Loss: 0.2974 Acc: 0.9041\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1718 Acc: 0.9405\n",
      "val Loss: 0.2879 Acc: 0.8953\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1694 Acc: 0.9413\n",
      "val Loss: 0.3503 Acc: 0.9021\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1770 Acc: 0.9379\n",
      "val Loss: 0.3379 Acc: 0.9075\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1740 Acc: 0.9386\n",
      "val Loss: 0.4522 Acc: 0.8878\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1743 Acc: 0.9446\n",
      "val Loss: 0.5574 Acc: 0.8572\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1586 Acc: 0.9458\n",
      "val Loss: 0.2825 Acc: 0.9109\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1545 Acc: 0.9473\n",
      "val Loss: 0.2687 Acc: 0.9075\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1488 Acc: 0.9478\n",
      "val Loss: 0.2564 Acc: 0.9130\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.2603 Acc: 0.9155\n",
      "val Loss: 0.3338 Acc: 0.9048\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.2017 Acc: 0.9369\n",
      "val Loss: 0.3017 Acc: 0.9157\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1846 Acc: 0.9432\n",
      "val Loss: 0.2603 Acc: 0.9157\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.7631 Acc: 0.8232\n",
      "val Loss: 0.3519 Acc: 0.8872\n",
      "Training complete in 3m 9s\n",
      "Best val Acc: 0.925221\n",
      "[4 4 4 4 4]\n",
      "[[ 3.0185163  -2.6709063  -1.3455262  -0.23610678  4.4431586  -8.567749  ]\n",
      " [ 0.43681976 -3.256823   -3.7350395   2.5898788   6.812459   -6.206282  ]\n",
      " [ 0.53687567 -3.2363987  -3.7682242   2.4976943   6.835698   -6.269879  ]\n",
      " [ 0.44587505 -3.299396   -3.7403483   2.5836961   6.904492   -6.277201  ]\n",
      " [ 0.4590189  -3.294892   -3.7132978   2.552673    6.872194   -6.281339  ]]\n"
     ]
    }
   ],
   "source": [
    "# Case 1. w/o data representation & RNN\n",
    "config = config1\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7821 Acc: 0.1978\n",
      "val Loss: 1.7576 Acc: 0.3297\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0517 Acc: 0.5593\n",
      "val Loss: 1.1752 Acc: 0.5724\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.7946 Acc: 0.6781\n",
      "val Loss: 0.9321 Acc: 0.7247\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.7382 Acc: 0.7223\n",
      "val Loss: 0.8463 Acc: 0.7424\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.5938 Acc: 0.7769\n",
      "val Loss: 0.7406 Acc: 0.7587\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5457 Acc: 0.7830\n",
      "val Loss: 0.6777 Acc: 0.7559\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.4712 Acc: 0.8152\n",
      "val Loss: 0.6655 Acc: 0.7791\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4101 Acc: 0.8456\n",
      "val Loss: 0.6466 Acc: 0.7933\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3734 Acc: 0.8546\n",
      "val Loss: 0.5965 Acc: 0.8226\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3122 Acc: 0.8898\n",
      "val Loss: 0.5677 Acc: 0.8457\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.3138 Acc: 0.8919\n",
      "val Loss: 0.5175 Acc: 0.8654\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2393 Acc: 0.9216\n",
      "val Loss: 0.4102 Acc: 0.8973\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2519 Acc: 0.9192\n",
      "val Loss: 0.3028 Acc: 0.8973\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2013 Acc: 0.9340\n",
      "val Loss: 0.2560 Acc: 0.9252\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1814 Acc: 0.9401\n",
      "val Loss: 0.3428 Acc: 0.9137\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1544 Acc: 0.9500\n",
      "val Loss: 0.2403 Acc: 0.9225\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1428 Acc: 0.9507\n",
      "val Loss: 0.2599 Acc: 0.9239\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1327 Acc: 0.9546\n",
      "val Loss: 0.3316 Acc: 0.9198\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1520 Acc: 0.9503\n",
      "val Loss: 0.3697 Acc: 0.9103\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1358 Acc: 0.9548\n",
      "val Loss: 0.3540 Acc: 0.9177\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.2023 Acc: 0.9347\n",
      "val Loss: 0.3751 Acc: 0.9177\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1358 Acc: 0.9514\n",
      "val Loss: 0.2486 Acc: 0.9300\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1135 Acc: 0.9561\n",
      "val Loss: 0.2405 Acc: 0.9307\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1692 Acc: 0.9373\n",
      "val Loss: 0.2841 Acc: 0.9164\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1088 Acc: 0.9570\n",
      "val Loss: 0.2559 Acc: 0.9286\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1059 Acc: 0.9604\n",
      "val Loss: 0.2313 Acc: 0.9334\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1033 Acc: 0.9599\n",
      "val Loss: 0.2243 Acc: 0.9293\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1072 Acc: 0.9583\n",
      "val Loss: 0.3012 Acc: 0.8994\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0918 Acc: 0.9626\n",
      "val Loss: 0.2494 Acc: 0.9245\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0946 Acc: 0.9621\n",
      "val Loss: 0.2750 Acc: 0.9184\n",
      "Training complete in 3m 17s\n",
      "Best val Acc: 0.936778\n",
      "[4 4 4 4 4]\n",
      "[[-0.04416232 -1.5564657  -2.6390538   0.23135655  6.2844687  -6.211173  ]\n",
      " [-0.13038693 -1.6591768  -2.58128     0.29581937  6.2984447  -6.2150154 ]\n",
      " [-0.1676458  -1.7086916  -2.5640073   0.33197075  6.3000836  -6.2027993 ]\n",
      " [-0.16678253 -1.7073661  -2.5630195   0.33032888  6.30126    -6.206491  ]\n",
      " [-0.12793724 -1.6679486  -2.5685513   0.28996184  6.2983913  -6.212824  ]]\n"
     ]
    }
   ],
   "source": [
    "# Case 2. w/o data representation & LSTM\n",
    "config = config2\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7674f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7403 Acc: 0.3537\n",
      "val Loss: 1.6700 Acc: 0.4555\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9985 Acc: 0.5676\n",
      "val Loss: 1.0738 Acc: 0.5540\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.8697 Acc: 0.6382\n",
      "val Loss: 0.8905 Acc: 0.6540\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.4917 Acc: 0.8536\n",
      "val Loss: 0.4752 Acc: 0.8858\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2645 Acc: 0.9277\n",
      "val Loss: 0.3380 Acc: 0.9021\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1948 Acc: 0.9408\n",
      "val Loss: 0.2771 Acc: 0.9245\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1731 Acc: 0.9388\n",
      "val Loss: 0.2624 Acc: 0.9293\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1524 Acc: 0.9456\n",
      "val Loss: 0.2625 Acc: 0.9300\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1442 Acc: 0.9464\n",
      "val Loss: 0.2558 Acc: 0.9307\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1337 Acc: 0.9488\n",
      "val Loss: 0.2497 Acc: 0.9361\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1266 Acc: 0.9519\n",
      "val Loss: 0.2436 Acc: 0.9341\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1228 Acc: 0.9527\n",
      "val Loss: 0.2503 Acc: 0.9320\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1244 Acc: 0.9512\n",
      "val Loss: 0.2425 Acc: 0.9341\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1145 Acc: 0.9566\n",
      "val Loss: 0.2410 Acc: 0.9375\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1163 Acc: 0.9527\n",
      "val Loss: 0.2477 Acc: 0.9341\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1115 Acc: 0.9531\n",
      "val Loss: 0.2394 Acc: 0.9361\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1145 Acc: 0.9515\n",
      "val Loss: 0.2444 Acc: 0.9327\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1048 Acc: 0.9558\n",
      "val Loss: 0.2421 Acc: 0.9327\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1034 Acc: 0.9551\n",
      "val Loss: 0.2421 Acc: 0.9327\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1025 Acc: 0.9566\n",
      "val Loss: 0.2421 Acc: 0.9341\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0990 Acc: 0.9585\n",
      "val Loss: 0.2459 Acc: 0.9334\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1042 Acc: 0.9551\n",
      "val Loss: 0.2447 Acc: 0.9341\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0996 Acc: 0.9577\n",
      "val Loss: 0.2457 Acc: 0.9225\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0971 Acc: 0.9590\n",
      "val Loss: 0.2304 Acc: 0.9381\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0988 Acc: 0.9575\n",
      "val Loss: 0.2310 Acc: 0.9375\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0958 Acc: 0.9597\n",
      "val Loss: 0.2485 Acc: 0.9334\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0990 Acc: 0.9604\n",
      "val Loss: 0.2376 Acc: 0.9388\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0932 Acc: 0.9616\n",
      "val Loss: 0.2362 Acc: 0.9347\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0974 Acc: 0.9606\n",
      "val Loss: 0.2371 Acc: 0.9361\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0936 Acc: 0.9604\n",
      "val Loss: 0.2476 Acc: 0.9334\n",
      "Training complete in 3m 8s\n",
      "Best val Acc: 0.940857\n",
      "[4 4 4 4 4]\n",
      "[[ 0.90820694 -1.5440568  -8.312525    0.61867917  6.9758263  -7.0844517 ]\n",
      " [ 0.872182   -1.5198749  -8.271869    0.6334086   6.942082   -7.0175853 ]\n",
      " [ 0.87774587 -1.5120534  -8.248257    0.61669725  6.9415245  -7.0360622 ]\n",
      " [ 0.88496083 -1.5213611  -8.2281      0.6151486   6.94689    -7.0753155 ]\n",
      " [ 0.8851025  -1.5039475  -8.24159     0.60359526  6.9388146  -7.032606  ]]\n"
     ]
    }
   ],
   "source": [
    "# Case 3. w/o data representation & GRU\n",
    "config = config3\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59275e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.5987 Acc: 0.5013\n",
      "val Loss: 1.3670 Acc: 0.6084\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.5261 Acc: 0.8019\n",
      "val Loss: 0.6510 Acc: 0.7797\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.3782 Acc: 0.8662\n",
      "val Loss: 0.5126 Acc: 0.8239\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.2891 Acc: 0.9051\n",
      "val Loss: 0.4063 Acc: 0.8817\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2326 Acc: 0.9254\n",
      "val Loss: 0.3486 Acc: 0.8926\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1978 Acc: 0.9345\n",
      "val Loss: 0.3156 Acc: 0.8967\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1759 Acc: 0.9415\n",
      "val Loss: 0.2921 Acc: 0.9014\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1598 Acc: 0.9452\n",
      "val Loss: 0.2803 Acc: 0.9055\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1453 Acc: 0.9495\n",
      "val Loss: 0.2741 Acc: 0.9007\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1322 Acc: 0.9527\n",
      "val Loss: 0.2675 Acc: 0.9123\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1259 Acc: 0.9539\n",
      "val Loss: 0.2670 Acc: 0.9198\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1179 Acc: 0.9560\n",
      "val Loss: 0.2752 Acc: 0.9225\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1124 Acc: 0.9544\n",
      "val Loss: 0.2663 Acc: 0.9218\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1077 Acc: 0.9563\n",
      "val Loss: 0.2838 Acc: 0.9055\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1014 Acc: 0.9561\n",
      "val Loss: 0.2826 Acc: 0.9130\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0972 Acc: 0.9594\n",
      "val Loss: 0.2958 Acc: 0.9096\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0936 Acc: 0.9616\n",
      "val Loss: 0.3022 Acc: 0.9103\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0908 Acc: 0.9614\n",
      "val Loss: 0.2979 Acc: 0.9103\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0877 Acc: 0.9624\n",
      "val Loss: 0.3101 Acc: 0.9109\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0846 Acc: 0.9648\n",
      "val Loss: 0.3149 Acc: 0.9116\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0825 Acc: 0.9645\n",
      "val Loss: 0.3291 Acc: 0.9109\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.0793 Acc: 0.9651\n",
      "val Loss: 0.3333 Acc: 0.9116\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0780 Acc: 0.9658\n",
      "val Loss: 0.3464 Acc: 0.9130\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0763 Acc: 0.9658\n",
      "val Loss: 0.3428 Acc: 0.9123\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0756 Acc: 0.9672\n",
      "val Loss: 0.3695 Acc: 0.9109\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0710 Acc: 0.9682\n",
      "val Loss: 0.3517 Acc: 0.9109\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0694 Acc: 0.9674\n",
      "val Loss: 0.3726 Acc: 0.9123\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0683 Acc: 0.9696\n",
      "val Loss: 0.3947 Acc: 0.9123\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0641 Acc: 0.9699\n",
      "val Loss: 0.3882 Acc: 0.9123\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0634 Acc: 0.9719\n",
      "val Loss: 0.3761 Acc: 0.9123\n",
      "Training complete in 0m 46s\n",
      "Best val Acc: 0.922502\n",
      "[4 4 4 4 4]\n",
      "[[ -0.0545887   -0.8739962  -10.135557     0.318584     6.984183\n",
      "  -14.561371  ]\n",
      " [ -0.33102724  -1.252699   -10.63112      2.2375767    7.984505\n",
      "  -14.874614  ]\n",
      " [ -0.65144193  -0.7991334  -10.766919     2.4478502    8.478192\n",
      "  -15.0501375 ]\n",
      " [ -0.6649623   -0.51520693 -10.887545     2.5151854    8.7294035\n",
      "  -15.23084   ]\n",
      " [ -0.63186735  -0.34990746 -11.049662     2.696743     9.054423\n",
      "  -15.535     ]]\n"
     ]
    }
   ],
   "source": [
    "# Case 4. w/o data representation & CNN_1D\n",
    "config = config4\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b370aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.8038 Acc: 0.1717\n",
      "val Loss: 1.7895 Acc: 0.1937\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.7943 Acc: 0.1777\n",
      "val Loss: 1.7870 Acc: 0.1971\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 1.7936 Acc: 0.1750\n",
      "val Loss: 1.7873 Acc: 0.2039\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 1.7923 Acc: 0.1753\n",
      "val Loss: 1.7874 Acc: 0.2060\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 1.7918 Acc: 0.1785\n",
      "val Loss: 1.7874 Acc: 0.2060\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 1.7925 Acc: 0.1755\n",
      "val Loss: 1.7873 Acc: 0.2026\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 1.7925 Acc: 0.1741\n",
      "val Loss: 1.7873 Acc: 0.2053\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 1.7912 Acc: 0.1831\n",
      "val Loss: 1.7873 Acc: 0.2046\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 1.7910 Acc: 0.1738\n",
      "val Loss: 1.7873 Acc: 0.2046\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 1.7912 Acc: 0.1728\n",
      "val Loss: 1.7873 Acc: 0.2039\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 1.7908 Acc: 0.1811\n",
      "val Loss: 1.7872 Acc: 0.2005\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 1.7913 Acc: 0.1799\n",
      "val Loss: 1.7873 Acc: 0.2053\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 1.7910 Acc: 0.1794\n",
      "val Loss: 1.7874 Acc: 0.2012\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 1.7903 Acc: 0.1850\n",
      "val Loss: 1.7873 Acc: 0.2005\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 1.7899 Acc: 0.1887\n",
      "val Loss: 1.7873 Acc: 0.2019\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 1.7894 Acc: 0.1903\n",
      "val Loss: 1.7874 Acc: 0.1999\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 1.7906 Acc: 0.1796\n",
      "val Loss: 1.7875 Acc: 0.1992\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 1.7891 Acc: 0.1870\n",
      "val Loss: 1.7875 Acc: 0.1999\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 1.7902 Acc: 0.1823\n",
      "val Loss: 1.7874 Acc: 0.1971\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 1.7905 Acc: 0.1847\n",
      "val Loss: 1.7875 Acc: 0.1944\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 1.7893 Acc: 0.1857\n",
      "val Loss: 1.7875 Acc: 0.1944\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 1.7888 Acc: 0.1853\n",
      "val Loss: 1.7876 Acc: 0.1971\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 1.7888 Acc: 0.1876\n",
      "val Loss: 1.7876 Acc: 0.1958\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 1.7900 Acc: 0.1806\n",
      "val Loss: 1.7877 Acc: 0.1924\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 1.7888 Acc: 0.1876\n",
      "val Loss: 1.7878 Acc: 0.1903\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 1.7893 Acc: 0.1867\n",
      "val Loss: 1.7878 Acc: 0.1897\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 1.7885 Acc: 0.1884\n",
      "val Loss: 1.7878 Acc: 0.1883\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 1.7892 Acc: 0.1855\n",
      "val Loss: 1.7879 Acc: 0.1876\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 1.7882 Acc: 0.1889\n",
      "val Loss: 1.7880 Acc: 0.1897\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 1.7886 Acc: 0.1842\n",
      "val Loss: 1.7880 Acc: 0.1897\n",
      "Training complete in 0m 21s\n",
      "Best val Acc: 0.209381\n",
      "[4 4 4 0 4]\n",
      "[[0.         0.         0.         0.         0.20967467 0.11200541]\n",
      " [0.         0.         0.         0.         0.09573306 0.05175306]\n",
      " [0.05794232 0.         0.         0.         0.0742238  0.        ]\n",
      " [0.07968983 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.05837218 0.0251669 ]]\n"
     ]
    }
   ],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
