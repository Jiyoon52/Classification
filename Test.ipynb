{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import main_classificaiton as mc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c4dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & RNN model \n",
    "config1 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'RNN', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation &LSTM model \n",
    "config2 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & GRU model \n",
    "config3 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & CNN_1D model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "# 특징 벡터의 사이즈 = 20 이라고 가정\n",
    "config5 = {\n",
    "        'with_representation': True, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'input_representation' : 0, # 예를 들면 (80, 20) 차원의 벡터 (80은 window_length에 따른 관측치 수, 20은 representation 특징벡터 차원 수)를 넣어야 함. 지금은 loader부분에서 random값들어가 있음\n",
    "            'drop_out' : 0.2, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'X_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'X_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance x input_dims x window_size) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564b0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6580 Acc: 0.3719\n",
      "val Loss: 1.4532 Acc: 0.3678\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0048 Acc: 0.5598\n",
      "val Loss: 1.1178 Acc: 0.5146\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9582 Acc: 0.5775\n",
      "val Loss: 1.0061 Acc: 0.5622\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.9304 Acc: 0.6009\n",
      "val Loss: 1.0273 Acc: 0.5751\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.8618 Acc: 0.6368\n",
      "val Loss: 1.0039 Acc: 0.6451\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.6365 Acc: 0.7465\n",
      "val Loss: 0.6684 Acc: 0.7539\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5134 Acc: 0.7936\n",
      "val Loss: 0.5338 Acc: 0.7974\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4148 Acc: 0.8461\n",
      "val Loss: 0.4598 Acc: 0.8273\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3641 Acc: 0.8738\n",
      "val Loss: 0.4156 Acc: 0.8450\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3200 Acc: 0.8993\n",
      "val Loss: 0.4285 Acc: 0.8980\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2832 Acc: 0.9109\n",
      "val Loss: 0.4048 Acc: 0.8939\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2760 Acc: 0.9102\n",
      "val Loss: 0.3839 Acc: 0.8899\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2971 Acc: 0.8985\n",
      "val Loss: 0.3319 Acc: 0.8939\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2518 Acc: 0.9131\n",
      "val Loss: 0.3767 Acc: 0.8763\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.2625 Acc: 0.9094\n",
      "val Loss: 0.3208 Acc: 0.9184\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.2092 Acc: 0.9303\n",
      "val Loss: 0.2485 Acc: 0.9198\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1995 Acc: 0.9345\n",
      "val Loss: 0.2492 Acc: 0.9273\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.2330 Acc: 0.9201\n",
      "val Loss: 0.2847 Acc: 0.9075\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1921 Acc: 0.9374\n",
      "val Loss: 0.2533 Acc: 0.9245\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1973 Acc: 0.9337\n",
      "val Loss: 0.2374 Acc: 0.9327\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1878 Acc: 0.9337\n",
      "val Loss: 0.2627 Acc: 0.9171\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.3121 Acc: 0.8861\n",
      "val Loss: 0.3813 Acc: 0.8844\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1984 Acc: 0.9335\n",
      "val Loss: 0.2685 Acc: 0.9096\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.2256 Acc: 0.9233\n",
      "val Loss: 0.2897 Acc: 0.9130\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1904 Acc: 0.9366\n",
      "val Loss: 0.2534 Acc: 0.9198\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1736 Acc: 0.9393\n",
      "val Loss: 0.2435 Acc: 0.9225\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1682 Acc: 0.9400\n",
      "val Loss: 0.2627 Acc: 0.9123\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1476 Acc: 0.9492\n",
      "val Loss: 0.2366 Acc: 0.9320\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1661 Acc: 0.9437\n",
      "val Loss: 0.2562 Acc: 0.9293\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 1.5151 Acc: 0.4683\n",
      "val Loss: 1.2832 Acc: 0.4670\n",
      "Training complete in 3m 1s\n",
      "Best val Acc: 0.935418\n"
     ]
    }
   ],
   "source": [
    "# Case 1. w/o data representation & RNN\n",
    "config = config1\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "result = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "preds = result['preds']  # shape : (2947, )\n",
    "probs = result['probs']  # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7742 Acc: 0.3477\n",
      "val Loss: 1.7438 Acc: 0.3698\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9785 Acc: 0.6058\n",
      "val Loss: 1.0983 Acc: 0.5846\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.7324 Acc: 0.6924\n",
      "val Loss: 0.8869 Acc: 0.7131\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.6090 Acc: 0.7344\n",
      "val Loss: 0.8187 Acc: 0.6900\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.5944 Acc: 0.7301\n",
      "val Loss: 0.7354 Acc: 0.7383\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5000 Acc: 0.7803\n",
      "val Loss: 0.6883 Acc: 0.7451\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.3777 Acc: 0.8461\n",
      "val Loss: 0.6054 Acc: 0.7886\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.3114 Acc: 0.9032\n",
      "val Loss: 0.5671 Acc: 0.8613\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.4221 Acc: 0.8526\n",
      "val Loss: 0.5538 Acc: 0.8538\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.2506 Acc: 0.9242\n",
      "val Loss: 0.4324 Acc: 0.8749\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2291 Acc: 0.9298\n",
      "val Loss: 0.3808 Acc: 0.8885\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2571 Acc: 0.9136\n",
      "val Loss: 0.3531 Acc: 0.8919\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1895 Acc: 0.9396\n",
      "val Loss: 0.3331 Acc: 0.8933\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.4456 Acc: 0.8606\n",
      "val Loss: 0.3339 Acc: 0.8899\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1590 Acc: 0.9464\n",
      "val Loss: 0.3487 Acc: 0.8933\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1419 Acc: 0.9486\n",
      "val Loss: 0.3790 Acc: 0.8926\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1380 Acc: 0.9510\n",
      "val Loss: 0.3282 Acc: 0.9021\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1358 Acc: 0.9519\n",
      "val Loss: 0.3590 Acc: 0.9021\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1184 Acc: 0.9583\n",
      "val Loss: 0.3365 Acc: 0.9116\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1157 Acc: 0.9575\n",
      "val Loss: 0.3392 Acc: 0.9116\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1216 Acc: 0.9560\n",
      "val Loss: 0.3444 Acc: 0.9089\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1181 Acc: 0.9543\n",
      "val Loss: 0.3645 Acc: 0.9089\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1045 Acc: 0.9600\n",
      "val Loss: 0.3708 Acc: 0.8946\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1043 Acc: 0.9600\n",
      "val Loss: 0.3630 Acc: 0.9096\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1142 Acc: 0.9580\n",
      "val Loss: 0.2822 Acc: 0.9089\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1077 Acc: 0.9585\n",
      "val Loss: 0.3347 Acc: 0.9123\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1057 Acc: 0.9594\n",
      "val Loss: 0.3304 Acc: 0.9048\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1144 Acc: 0.9583\n",
      "val Loss: 0.2999 Acc: 0.9096\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1046 Acc: 0.9621\n",
      "val Loss: 0.3003 Acc: 0.9116\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.1133 Acc: 0.9577\n",
      "val Loss: 0.3684 Acc: 0.8939\n",
      "Training complete in 5m 34s\n",
      "Best val Acc: 0.912305\n"
     ]
    }
   ],
   "source": [
    "# Case 2. w/o data representation & LSTM\n",
    "config = config2\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "result = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "preds = result['preds']  # shape : (2947, )\n",
    "probs = result['probs']  # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7674f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7494 Acc: 0.2773\n",
      "val Loss: 1.6919 Acc: 0.4385\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9816 Acc: 0.5771\n",
      "val Loss: 1.1222 Acc: 0.5676\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.8454 Acc: 0.6388\n",
      "val Loss: 0.8501 Acc: 0.7022\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.6690 Acc: 0.7356\n",
      "val Loss: 0.6263 Acc: 0.7607\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.4714 Acc: 0.8198\n",
      "val Loss: 0.4925 Acc: 0.8056\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.3678 Acc: 0.8939\n",
      "val Loss: 0.3986 Acc: 0.8783\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.2674 Acc: 0.9230\n",
      "val Loss: 0.3501 Acc: 0.8729\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.2195 Acc: 0.9306\n",
      "val Loss: 0.3100 Acc: 0.8967\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.2101 Acc: 0.9282\n",
      "val Loss: 0.3474 Acc: 0.8776\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.2173 Acc: 0.9282\n",
      "val Loss: 0.3525 Acc: 0.8817\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1955 Acc: 0.9316\n",
      "val Loss: 0.3506 Acc: 0.8634\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1797 Acc: 0.9361\n",
      "val Loss: 0.2783 Acc: 0.9021\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1914 Acc: 0.9323\n",
      "val Loss: 0.2588 Acc: 0.9205\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1760 Acc: 0.9337\n",
      "val Loss: 0.2745 Acc: 0.9103\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1643 Acc: 0.9415\n",
      "val Loss: 0.3139 Acc: 0.8865\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.2069 Acc: 0.9259\n",
      "val Loss: 0.2857 Acc: 0.9177\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1642 Acc: 0.9410\n",
      "val Loss: 0.2591 Acc: 0.9157\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1485 Acc: 0.9471\n",
      "val Loss: 0.2487 Acc: 0.9184\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1388 Acc: 0.9500\n",
      "val Loss: 0.2538 Acc: 0.9266\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1281 Acc: 0.9560\n",
      "val Loss: 0.2441 Acc: 0.9232\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1184 Acc: 0.9594\n",
      "val Loss: 0.2416 Acc: 0.9293\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1122 Acc: 0.9621\n",
      "val Loss: 0.2510 Acc: 0.9218\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1104 Acc: 0.9604\n",
      "val Loss: 0.2398 Acc: 0.9327\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1066 Acc: 0.9621\n",
      "val Loss: 0.2405 Acc: 0.9313\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1036 Acc: 0.9626\n",
      "val Loss: 0.2358 Acc: 0.9347\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1018 Acc: 0.9638\n",
      "val Loss: 0.2369 Acc: 0.9354\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1010 Acc: 0.9619\n",
      "val Loss: 0.2404 Acc: 0.9347\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1123 Acc: 0.9595\n",
      "val Loss: 0.2401 Acc: 0.9347\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1016 Acc: 0.9617\n",
      "val Loss: 0.2388 Acc: 0.9347\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.1191 Acc: 0.9590\n",
      "val Loss: 0.2474 Acc: 0.9320\n",
      "Training complete in 5m 11s\n",
      "Best val Acc: 0.935418\n"
     ]
    }
   ],
   "source": [
    "# Case 3. w/o data representation & GRU\n",
    "config = config3\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "result = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "preds = result['preds']  # shape : (2947, )\n",
    "probs = result['probs']  # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59275e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6523 Acc: 0.4560\n",
      "val Loss: 1.4561 Acc: 0.6166\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.4959 Acc: 0.8111\n",
      "val Loss: 0.6206 Acc: 0.7886\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.3488 Acc: 0.8786\n",
      "val Loss: 0.4856 Acc: 0.8382\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.2673 Acc: 0.9087\n",
      "val Loss: 0.4041 Acc: 0.8878\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2140 Acc: 0.9276\n",
      "val Loss: 0.3621 Acc: 0.8946\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1831 Acc: 0.9364\n",
      "val Loss: 0.3286 Acc: 0.9137\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1601 Acc: 0.9415\n",
      "val Loss: 0.3232 Acc: 0.9103\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1469 Acc: 0.9456\n",
      "val Loss: 0.3089 Acc: 0.9164\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1319 Acc: 0.9507\n",
      "val Loss: 0.3083 Acc: 0.9184\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1224 Acc: 0.9524\n",
      "val Loss: 0.3063 Acc: 0.9137\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1168 Acc: 0.9541\n",
      "val Loss: 0.2974 Acc: 0.9177\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1102 Acc: 0.9575\n",
      "val Loss: 0.2907 Acc: 0.9198\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1039 Acc: 0.9568\n",
      "val Loss: 0.2901 Acc: 0.9150\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.0980 Acc: 0.9599\n",
      "val Loss: 0.2890 Acc: 0.9150\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.0948 Acc: 0.9621\n",
      "val Loss: 0.2874 Acc: 0.9143\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0936 Acc: 0.9629\n",
      "val Loss: 0.2867 Acc: 0.9218\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0889 Acc: 0.9633\n",
      "val Loss: 0.2914 Acc: 0.9266\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0864 Acc: 0.9640\n",
      "val Loss: 0.2890 Acc: 0.9252\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0821 Acc: 0.9633\n",
      "val Loss: 0.2894 Acc: 0.9273\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0804 Acc: 0.9638\n",
      "val Loss: 0.2910 Acc: 0.9300\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0778 Acc: 0.9653\n",
      "val Loss: 0.2941 Acc: 0.9327\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.0760 Acc: 0.9657\n",
      "val Loss: 0.3046 Acc: 0.9259\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0735 Acc: 0.9670\n",
      "val Loss: 0.3056 Acc: 0.9273\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0729 Acc: 0.9672\n",
      "val Loss: 0.3055 Acc: 0.9259\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0707 Acc: 0.9674\n",
      "val Loss: 0.3120 Acc: 0.9279\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0694 Acc: 0.9674\n",
      "val Loss: 0.3164 Acc: 0.9245\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0672 Acc: 0.9701\n",
      "val Loss: 0.3228 Acc: 0.9245\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0664 Acc: 0.9697\n",
      "val Loss: 0.3249 Acc: 0.9279\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0649 Acc: 0.9711\n",
      "val Loss: 0.3282 Acc: 0.9266\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0628 Acc: 0.9714\n",
      "val Loss: 0.3323 Acc: 0.9273\n",
      "Training complete in 0m 47s\n",
      "Best val Acc: 0.934738\n"
     ]
    }
   ],
   "source": [
    "# Case 4. w/o data representation & CNN_1D\n",
    "config = config4\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "result = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "preds = result['preds']  # shape : (2947, )\n",
    "probs = result['probs']  # shape : (2947, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b370aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.8125 Acc: 0.1697\n",
      "val Loss: 1.8002 Acc: 0.1720\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.7975 Acc: 0.1722\n",
      "val Loss: 1.7939 Acc: 0.1693\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 1.7943 Acc: 0.1823\n",
      "val Loss: 1.7934 Acc: 0.1788\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 1.7921 Acc: 0.1777\n",
      "val Loss: 1.7937 Acc: 0.1822\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 1.7915 Acc: 0.1835\n",
      "val Loss: 1.7936 Acc: 0.1774\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 1.7908 Acc: 0.1842\n",
      "val Loss: 1.7933 Acc: 0.1734\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 1.7905 Acc: 0.1838\n",
      "val Loss: 1.7931 Acc: 0.1768\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 1.7909 Acc: 0.1842\n",
      "val Loss: 1.7928 Acc: 0.1808\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 1.7905 Acc: 0.1825\n",
      "val Loss: 1.7928 Acc: 0.1781\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 1.7905 Acc: 0.1831\n",
      "val Loss: 1.7926 Acc: 0.1740\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 1.7900 Acc: 0.1860\n",
      "val Loss: 1.7926 Acc: 0.1754\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 1.7911 Acc: 0.1796\n",
      "val Loss: 1.7926 Acc: 0.1720\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 1.7907 Acc: 0.1826\n",
      "val Loss: 1.7926 Acc: 0.1700\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 1.7905 Acc: 0.1853\n",
      "val Loss: 1.7926 Acc: 0.1720\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 1.7898 Acc: 0.1853\n",
      "val Loss: 1.7927 Acc: 0.1720\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 1.7901 Acc: 0.1835\n",
      "val Loss: 1.7926 Acc: 0.1740\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 1.7906 Acc: 0.1814\n",
      "val Loss: 1.7926 Acc: 0.1761\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 1.7896 Acc: 0.1872\n",
      "val Loss: 1.7927 Acc: 0.1740\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 1.7891 Acc: 0.1915\n",
      "val Loss: 1.7928 Acc: 0.1747\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 1.7897 Acc: 0.1852\n",
      "val Loss: 1.7926 Acc: 0.1754\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 1.7900 Acc: 0.1808\n",
      "val Loss: 1.7926 Acc: 0.1761\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 1.7894 Acc: 0.1859\n",
      "val Loss: 1.7926 Acc: 0.1747\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 1.7898 Acc: 0.1845\n",
      "val Loss: 1.7926 Acc: 0.1781\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 1.7889 Acc: 0.1877\n",
      "val Loss: 1.7926 Acc: 0.1768\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 1.7892 Acc: 0.1831\n",
      "val Loss: 1.7926 Acc: 0.1768\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 1.7891 Acc: 0.1865\n",
      "val Loss: 1.7925 Acc: 0.1781\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 1.7888 Acc: 0.1860\n",
      "val Loss: 1.7926 Acc: 0.1774\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 1.7884 Acc: 0.1901\n",
      "val Loss: 1.7925 Acc: 0.1808\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 1.7891 Acc: 0.1826\n",
      "val Loss: 1.7926 Acc: 0.1781\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 1.7888 Acc: 0.1859\n",
      "val Loss: 1.7926 Acc: 0.1788\n",
      "Training complete in 0m 21s\n",
      "Best val Acc: 0.184228\n"
     ]
    }
   ],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "result = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "preds = result['preds']  # shape : (2947, )\n",
    "probs = result['probs']  # shape : (2947, 6)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
